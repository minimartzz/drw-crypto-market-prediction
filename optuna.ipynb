{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Date | User | Change Type | Remarks |  \n",
    "| ---- | ---- | ----------- | ------- |\n",
    "| 08/07/2025   | Martin | Create  | Notebook created to test optuna for hyperparameter search | \n",
    "| 09/07/2025   | Martin | Update  | Used Optuna to improve LightGBM and XGBoost models | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Content\n",
    "\n",
    "* [Vanilla Optuna](#vanilla-optuna)\n",
    "* [Optuna XGBoost](#optuna-xgboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import lightgbm as lgb\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 172)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>pca_1</th><th>pca_2</th><th>pca_3</th><th>pca_4</th><th>pca_5</th><th>pca_6</th><th>pca_7</th><th>pca_8</th><th>pca_9</th><th>pca_10</th><th>pca_11</th><th>pca_12</th><th>pca_13</th><th>pca_14</th><th>pca_15</th><th>pca_16</th><th>pca_17</th><th>pca_18</th><th>pca_19</th><th>pca_20</th><th>pca_21</th><th>pca_22</th><th>pca_23</th><th>pca_24</th><th>pca_25</th><th>pca_26</th><th>pca_27</th><th>pca_28</th><th>pca_29</th><th>pca_30</th><th>pca_31</th><th>pca_32</th><th>pca_33</th><th>pca_34</th><th>pca_35</th><th>pca_36</th><th>pca_37</th><th>&hellip;</th><th>pca_136</th><th>pca_137</th><th>pca_138</th><th>pca_139</th><th>pca_140</th><th>pca_141</th><th>pca_142</th><th>pca_143</th><th>pca_144</th><th>pca_145</th><th>pca_146</th><th>pca_147</th><th>pca_148</th><th>pca_149</th><th>pca_150</th><th>pca_151</th><th>pca_152</th><th>pca_153</th><th>pca_154</th><th>pca_155</th><th>pca_156</th><th>pca_157</th><th>pca_158</th><th>pca_159</th><th>pca_160</th><th>pca_161</th><th>pca_162</th><th>pca_163</th><th>pca_164</th><th>pca_165</th><th>pca_166</th><th>pca_167</th><th>pca_168</th><th>pca_169</th><th>pca_170</th><th>timestamp</th><th>label</th></tr><tr><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>&hellip;</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>str</td><td>f64</td></tr></thead><tbody><tr><td>-8.704309</td><td>5.45448</td><td>0.089441</td><td>-7.54084</td><td>4.768329</td><td>-5.736881</td><td>-0.231744</td><td>-1.788746</td><td>2.788266</td><td>-1.190636</td><td>3.148074</td><td>3.06826</td><td>6.837452</td><td>0.155804</td><td>-0.885875</td><td>-2.395842</td><td>3.13128</td><td>-4.266488</td><td>0.943026</td><td>0.60447</td><td>0.816785</td><td>-0.961067</td><td>-3.641479</td><td>-0.078829</td><td>-4.117839</td><td>4.6193</td><td>0.883802</td><td>-0.229885</td><td>0.600305</td><td>3.098696</td><td>-2.115549</td><td>1.951743</td><td>-0.103804</td><td>1.010359</td><td>1.52759</td><td>3.009872</td><td>0.625632</td><td>&hellip;</td><td>0.813653</td><td>1.265367</td><td>0.342502</td><td>1.045652</td><td>0.620349</td><td>-0.660641</td><td>0.201047</td><td>-0.643091</td><td>-0.105072</td><td>0.560754</td><td>-0.075368</td><td>1.723466</td><td>-0.617254</td><td>-1.380721</td><td>0.182322</td><td>-0.246119</td><td>-0.077405</td><td>0.11701</td><td>-1.024182</td><td>0.292968</td><td>-0.208723</td><td>-0.677946</td><td>0.70196</td><td>0.449714</td><td>-0.244457</td><td>-1.132325</td><td>0.164973</td><td>0.106318</td><td>0.376251</td><td>-0.74303</td><td>-0.336223</td><td>-1.084156</td><td>0.665739</td><td>-0.162322</td><td>0.858892</td><td>&quot;2023-03-01T00:00:00.000000000&quot;</td><td>0.562539</td></tr><tr><td>-7.994975</td><td>5.527279</td><td>-0.093258</td><td>-4.78567</td><td>4.097361</td><td>-6.208308</td><td>0.004089</td><td>-0.355855</td><td>3.798541</td><td>0.215877</td><td>2.648574</td><td>3.351467</td><td>6.158131</td><td>0.254169</td><td>-3.347221</td><td>-2.473193</td><td>3.618805</td><td>-3.161974</td><td>3.224999</td><td>2.054594</td><td>-2.296999</td><td>0.672556</td><td>-1.778871</td><td>-1.52334</td><td>1.743752</td><td>4.333566</td><td>-0.902184</td><td>0.029043</td><td>0.229918</td><td>2.181485</td><td>0.296175</td><td>1.67046</td><td>-0.227987</td><td>1.403915</td><td>2.228776</td><td>2.469899</td><td>-0.592644</td><td>&hellip;</td><td>-0.004203</td><td>0.837101</td><td>-0.419395</td><td>1.042492</td><td>-0.153447</td><td>-0.506816</td><td>0.006238</td><td>-0.800141</td><td>0.721092</td><td>-0.757491</td><td>0.083177</td><td>1.365879</td><td>1.094788</td><td>0.487046</td><td>0.05352</td><td>-0.871274</td><td>0.149816</td><td>0.448931</td><td>0.054529</td><td>-0.014539</td><td>-0.008121</td><td>0.415441</td><td>-0.12583</td><td>0.734486</td><td>0.668983</td><td>-0.910026</td><td>0.093044</td><td>0.553648</td><td>1.33117</td><td>-0.631829</td><td>0.189037</td><td>-0.679587</td><td>-0.257418</td><td>0.150572</td><td>0.55328</td><td>&quot;2023-03-01T00:01:00.000000000&quot;</td><td>0.533686</td></tr><tr><td>-8.26279</td><td>5.052642</td><td>-0.215007</td><td>-4.022985</td><td>3.920973</td><td>-5.534213</td><td>-0.192796</td><td>1.0202</td><td>3.404864</td><td>1.268972</td><td>2.083842</td><td>3.41862</td><td>5.318265</td><td>-0.448951</td><td>-3.372344</td><td>-2.696721</td><td>3.405499</td><td>-1.909767</td><td>3.035536</td><td>2.726676</td><td>-2.895715</td><td>0.675317</td><td>-2.672765</td><td>-1.462927</td><td>4.68873</td><td>3.224458</td><td>-1.63386</td><td>-0.420518</td><td>0.737464</td><td>1.673416</td><td>1.288468</td><td>1.626087</td><td>-0.205033</td><td>1.21317</td><td>2.613173</td><td>1.760396</td><td>-0.513233</td><td>&hellip;</td><td>0.739755</td><td>0.360366</td><td>0.232943</td><td>0.331362</td><td>0.253692</td><td>0.097951</td><td>-0.07237</td><td>-1.249928</td><td>-0.115931</td><td>-0.91212</td><td>-0.924596</td><td>2.581976</td><td>1.620534</td><td>0.208768</td><td>0.879783</td><td>-0.511462</td><td>0.159419</td><td>-0.455293</td><td>-0.267378</td><td>-0.10749</td><td>0.446583</td><td>0.192696</td><td>0.848871</td><td>0.237633</td><td>0.574078</td><td>-0.768855</td><td>0.269726</td><td>-0.37779</td><td>0.514883</td><td>-0.677345</td><td>-0.371701</td><td>-0.568106</td><td>0.161394</td><td>0.129997</td><td>0.53952</td><td>&quot;2023-03-01T00:02:00.000000000&quot;</td><td>0.546505</td></tr><tr><td>-6.583707</td><td>7.511057</td><td>-1.011146</td><td>-5.043764</td><td>4.93578</td><td>-5.846506</td><td>0.945893</td><td>-1.987165</td><td>5.037395</td><td>-0.61052</td><td>3.062758</td><td>3.185566</td><td>6.651355</td><td>0.209246</td><td>-4.044023</td><td>-2.209972</td><td>2.891386</td><td>-3.855405</td><td>3.003505</td><td>0.468633</td><td>-1.329728</td><td>0.101761</td><td>-1.862309</td><td>-2.455378</td><td>2.926416</td><td>4.623982</td><td>-2.465403</td><td>-0.558694</td><td>1.26826</td><td>1.792994</td><td>1.559252</td><td>2.209627</td><td>-0.713931</td><td>1.75982</td><td>1.519249</td><td>3.20797</td><td>-0.787381</td><td>&hellip;</td><td>0.43262</td><td>0.456949</td><td>0.522051</td><td>1.032057</td><td>-0.9966</td><td>-1.544666</td><td>-0.467818</td><td>-0.923329</td><td>0.817991</td><td>-1.338488</td><td>-0.29068</td><td>1.344751</td><td>1.463578</td><td>-0.179989</td><td>0.981197</td><td>-0.598796</td><td>0.044524</td><td>0.330884</td><td>0.217893</td><td>-0.140025</td><td>-0.897465</td><td>0.557288</td><td>0.562866</td><td>0.19119</td><td>0.245437</td><td>-0.888977</td><td>0.450078</td><td>0.407653</td><td>0.481479</td><td>0.334516</td><td>-0.449422</td><td>-0.513091</td><td>0.035653</td><td>0.093354</td><td>0.440441</td><td>&quot;2023-03-01T00:03:00.000000000&quot;</td><td>0.357703</td></tr><tr><td>-6.496762</td><td>7.126301</td><td>-0.582182</td><td>-5.279062</td><td>4.686467</td><td>-6.359052</td><td>0.802733</td><td>-0.713604</td><td>4.994975</td><td>0.220712</td><td>3.183836</td><td>2.947917</td><td>5.852149</td><td>-0.284797</td><td>-3.676434</td><td>-2.022073</td><td>2.813884</td><td>-2.542805</td><td>3.164651</td><td>2.014087</td><td>-1.716045</td><td>0.661284</td><td>-1.617872</td><td>-1.461303</td><td>2.399019</td><td>3.573622</td><td>-2.939042</td><td>-0.593127</td><td>1.061588</td><td>1.461763</td><td>1.08091</td><td>1.564789</td><td>-0.689344</td><td>1.887824</td><td>1.781988</td><td>2.113466</td><td>-1.470044</td><td>&hellip;</td><td>0.082776</td><td>0.211711</td><td>0.28985</td><td>1.328555</td><td>-0.475901</td><td>-1.322235</td><td>-0.234092</td><td>-0.81018</td><td>0.251531</td><td>-0.984722</td><td>-0.227</td><td>0.931093</td><td>0.977268</td><td>0.032714</td><td>0.881645</td><td>-1.053385</td><td>0.202635</td><td>0.38637</td><td>0.169513</td><td>-0.381335</td><td>-0.752441</td><td>0.279883</td><td>0.347725</td><td>0.548521</td><td>0.39888</td><td>-0.798777</td><td>0.355318</td><td>0.517521</td><td>0.384691</td><td>0.281629</td><td>-0.30855</td><td>-0.363938</td><td>-0.269014</td><td>0.295612</td><td>0.304394</td><td>&quot;2023-03-01T00:04:00.000000000&quot;</td><td>0.362452</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 172)\n",
       "┌───────────┬──────────┬───────────┬───────────┬───┬───────────┬──────────┬─────────────┬──────────┐\n",
       "│ pca_1     ┆ pca_2    ┆ pca_3     ┆ pca_4     ┆ … ┆ pca_169   ┆ pca_170  ┆ timestamp   ┆ label    │\n",
       "│ ---       ┆ ---      ┆ ---       ┆ ---       ┆   ┆ ---       ┆ ---      ┆ ---         ┆ ---      │\n",
       "│ f64       ┆ f64      ┆ f64       ┆ f64       ┆   ┆ f64       ┆ f64      ┆ str         ┆ f64      │\n",
       "╞═══════════╪══════════╪═══════════╪═══════════╪═══╪═══════════╪══════════╪═════════════╪══════════╡\n",
       "│ -8.704309 ┆ 5.45448  ┆ 0.089441  ┆ -7.54084  ┆ … ┆ -0.162322 ┆ 0.858892 ┆ 2023-03-01T ┆ 0.562539 │\n",
       "│           ┆          ┆           ┆           ┆   ┆           ┆          ┆ 00:00:00.00 ┆          │\n",
       "│           ┆          ┆           ┆           ┆   ┆           ┆          ┆ 0000000     ┆          │\n",
       "│ -7.994975 ┆ 5.527279 ┆ -0.093258 ┆ -4.78567  ┆ … ┆ 0.150572  ┆ 0.55328  ┆ 2023-03-01T ┆ 0.533686 │\n",
       "│           ┆          ┆           ┆           ┆   ┆           ┆          ┆ 00:01:00.00 ┆          │\n",
       "│           ┆          ┆           ┆           ┆   ┆           ┆          ┆ 0000000     ┆          │\n",
       "│ -8.26279  ┆ 5.052642 ┆ -0.215007 ┆ -4.022985 ┆ … ┆ 0.129997  ┆ 0.53952  ┆ 2023-03-01T ┆ 0.546505 │\n",
       "│           ┆          ┆           ┆           ┆   ┆           ┆          ┆ 00:02:00.00 ┆          │\n",
       "│           ┆          ┆           ┆           ┆   ┆           ┆          ┆ 0000000     ┆          │\n",
       "│ -6.583707 ┆ 7.511057 ┆ -1.011146 ┆ -5.043764 ┆ … ┆ 0.093354  ┆ 0.440441 ┆ 2023-03-01T ┆ 0.357703 │\n",
       "│           ┆          ┆           ┆           ┆   ┆           ┆          ┆ 00:03:00.00 ┆          │\n",
       "│           ┆          ┆           ┆           ┆   ┆           ┆          ┆ 0000000     ┆          │\n",
       "│ -6.496762 ┆ 7.126301 ┆ -0.582182 ┆ -5.279062 ┆ … ┆ 0.295612  ┆ 0.304394 ┆ 2023-03-01T ┆ 0.362452 │\n",
       "│           ┆          ┆           ┆           ┆   ┆           ┆          ┆ 00:04:00.00 ┆          │\n",
       "│           ┆          ┆           ┆           ┆   ┆           ┆          ┆ 0000000     ┆          │\n",
       "└───────────┴──────────┴───────────┴───────────┴───┴───────────┴──────────┴─────────────┴──────────┘"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "f = pl.read_csv(\"data/clean/pca_170.csv\")\n",
    "f.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process data\n",
    "df = f.drop('timestamp')\n",
    "y = df['label'].to_numpy()\n",
    "X = df.drop('label').to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Optuna hyperparameter search\n",
    "def objective(trial):\n",
    "  num_test = int(X.shape[0] * 0.2)\n",
    "  train_X, train_y = X[:-num_test], y[:-num_test]\n",
    "  valid_X, valid_y = X[-num_test:], y[-num_test:]\n",
    "\n",
    "  dtrain = lgb.Dataset(train_X, label=train_y)\n",
    "\n",
    "  params = {\n",
    "    \"objective\": \"regression\",\n",
    "    \"metric\": trial.suggest_categorical(\"metric\", ['rmse', 'l1', 'l2']),\n",
    "    \"verbosity\": -1,\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n",
    "    \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n",
    "    \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n",
    "    \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\n",
    "    \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\n",
    "    \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
    "    \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "  }\n",
    "\n",
    "  gbm = lgb.train(params, dtrain)\n",
    "  preds = gbm.predict(valid_X)\n",
    "  correlation = pearsonr(preds, valid_y).statistic\n",
    "  return correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-09 23:09:00,524] A new study created in memory with name: no-name-67e450d6-ea44-47ed-a1ee-855488ec1813\n",
      "[I 2025-07-09 23:09:09,683] Trial 0 finished with value: 0.08413283199459322 and parameters: {'metric': 'l2', 'lambda_l1': 0.0002477034873880323, 'lambda_l2': 0.00018793525532632586, 'num_leaves': 197, 'feature_fraction': 0.7370702857559748, 'bagging_fraction': 0.5121288299353159, 'bagging_freq': 4, 'min_child_samples': 45}. Best is trial 0 with value: 0.08413283199459322.\n",
      "[I 2025-07-09 23:09:14,652] Trial 1 finished with value: 0.0840769760896016 and parameters: {'metric': 'l1', 'lambda_l1': 0.0008557575405080566, 'lambda_l2': 2.6470771249965974, 'num_leaves': 172, 'feature_fraction': 0.5665313727728563, 'bagging_fraction': 0.7901199249805895, 'bagging_freq': 1, 'min_child_samples': 11}. Best is trial 0 with value: 0.08413283199459322.\n",
      "[I 2025-07-09 23:09:20,600] Trial 2 finished with value: 0.07408543977002335 and parameters: {'metric': 'l2', 'lambda_l1': 1.2274062645529953, 'lambda_l2': 3.1472302796288457e-08, 'num_leaves': 169, 'feature_fraction': 0.8174384767313145, 'bagging_fraction': 0.4181125849846867, 'bagging_freq': 2, 'min_child_samples': 21}. Best is trial 0 with value: 0.08413283199459322.\n",
      "[I 2025-07-09 23:09:26,212] Trial 3 finished with value: 0.0863263354902292 and parameters: {'metric': 'rmse', 'lambda_l1': 9.591281230760622e-05, 'lambda_l2': 0.001997381760123999, 'num_leaves': 137, 'feature_fraction': 0.6242186883501583, 'bagging_fraction': 0.6530574382353185, 'bagging_freq': 1, 'min_child_samples': 17}. Best is trial 3 with value: 0.0863263354902292.\n",
      "[I 2025-07-09 23:09:37,522] Trial 4 finished with value: 0.08066288165366113 and parameters: {'metric': 'l1', 'lambda_l1': 0.1865872390830396, 'lambda_l2': 0.2996554717146668, 'num_leaves': 101, 'feature_fraction': 0.4704104566005469, 'bagging_fraction': 0.5099917895340454, 'bagging_freq': 3, 'min_child_samples': 79}. Best is trial 3 with value: 0.0863263354902292.\n",
      "[I 2025-07-09 23:09:56,760] Trial 5 finished with value: 0.06918006476032895 and parameters: {'metric': 'l1', 'lambda_l1': 0.0010082170374138674, 'lambda_l2': 1.3473005635857403e-06, 'num_leaves': 144, 'feature_fraction': 0.6370205585965132, 'bagging_fraction': 0.6864774522354684, 'bagging_freq': 2, 'min_child_samples': 39}. Best is trial 3 with value: 0.0863263354902292.\n",
      "[I 2025-07-09 23:10:05,848] Trial 6 finished with value: 0.0900992623831805 and parameters: {'metric': 'l1', 'lambda_l1': 3.20848806034958e-08, 'lambda_l2': 0.3673772130671187, 'num_leaves': 111, 'feature_fraction': 0.5210111931699302, 'bagging_fraction': 0.6604389273936626, 'bagging_freq': 4, 'min_child_samples': 49}. Best is trial 6 with value: 0.0900992623831805.\n",
      "[I 2025-07-09 23:10:10,447] Trial 7 finished with value: 0.07980723633393483 and parameters: {'metric': 'l1', 'lambda_l1': 1.6705230159617724e-08, 'lambda_l2': 0.02772246514710554, 'num_leaves': 72, 'feature_fraction': 0.6869323035601318, 'bagging_fraction': 0.7629300527927982, 'bagging_freq': 2, 'min_child_samples': 51}. Best is trial 6 with value: 0.0900992623831805.\n",
      "[I 2025-07-09 23:10:18,393] Trial 8 finished with value: 0.06763269369175264 and parameters: {'metric': 'l2', 'lambda_l1': 2.148708658574403e-05, 'lambda_l2': 6.717502918518249e-08, 'num_leaves': 75, 'feature_fraction': 0.9442194894513251, 'bagging_fraction': 0.7127190144016988, 'bagging_freq': 6, 'min_child_samples': 80}. Best is trial 6 with value: 0.0900992623831805.\n",
      "[I 2025-07-09 23:10:25,394] Trial 9 finished with value: 0.07246920661392997 and parameters: {'metric': 'l1', 'lambda_l1': 1.1602699463391893e-07, 'lambda_l2': 0.09276515322318986, 'num_leaves': 182, 'feature_fraction': 0.46000528094361015, 'bagging_fraction': 0.8178038585727221, 'bagging_freq': 6, 'min_child_samples': 25}. Best is trial 6 with value: 0.0900992623831805.\n",
      "[I 2025-07-09 23:10:27,446] Trial 10 finished with value: 0.07070853583229464 and parameters: {'metric': 'rmse', 'lambda_l1': 1.0466968941613528e-06, 'lambda_l2': 9.382252716201727, 'num_leaves': 4, 'feature_fraction': 0.40166527096708743, 'bagging_fraction': 0.9049364110078515, 'bagging_freq': 7, 'min_child_samples': 98}. Best is trial 6 with value: 0.0900992623831805.\n",
      "[I 2025-07-09 23:10:36,571] Trial 11 finished with value: 0.06942523593585082 and parameters: {'metric': 'rmse', 'lambda_l1': 2.6938726644909798e-06, 'lambda_l2': 0.0011587363991057878, 'num_leaves': 250, 'feature_fraction': 0.572272149745159, 'bagging_fraction': 0.6201102446574857, 'bagging_freq': 4, 'min_child_samples': 68}. Best is trial 6 with value: 0.0900992623831805.\n",
      "[I 2025-07-09 23:10:43,627] Trial 12 finished with value: 0.07040366177091116 and parameters: {'metric': 'rmse', 'lambda_l1': 0.0312833681355323, 'lambda_l2': 0.00030363061948716886, 'num_leaves': 117, 'feature_fraction': 0.5568065787343758, 'bagging_fraction': 0.6232064946393833, 'bagging_freq': 5, 'min_child_samples': 33}. Best is trial 6 with value: 0.0900992623831805.\n",
      "[I 2025-07-09 23:10:50,022] Trial 13 finished with value: 0.06997008405374527 and parameters: {'metric': 'rmse', 'lambda_l1': 3.993193071745147e-05, 'lambda_l2': 0.006676768304752799, 'num_leaves': 20, 'feature_fraction': 0.8131384856948847, 'bagging_fraction': 0.979147571558812, 'bagging_freq': 1, 'min_child_samples': 6}. Best is trial 6 with value: 0.0900992623831805.\n",
      "[I 2025-07-09 23:10:55,321] Trial 14 finished with value: 0.08051754989089699 and parameters: {'metric': 'rmse', 'lambda_l1': 1.006083771316877e-08, 'lambda_l2': 2.199629002748737e-05, 'num_leaves': 59, 'feature_fraction': 0.6341700139916254, 'bagging_fraction': 0.6012169149768327, 'bagging_freq': 3, 'min_child_samples': 64}. Best is trial 6 with value: 0.0900992623831805.\n",
      "[I 2025-07-09 23:11:05,701] Trial 15 finished with value: 0.0812198911696847 and parameters: {'metric': 'l1', 'lambda_l1': 4.5953284733331047e-07, 'lambda_l2': 0.8175767863441649, 'num_leaves': 229, 'feature_fraction': 0.4901008749761393, 'bagging_fraction': 0.5309993653361891, 'bagging_freq': 5, 'min_child_samples': 24}. Best is trial 6 with value: 0.0900992623831805.\n",
      "[I 2025-07-09 23:11:25,602] Trial 16 finished with value: 0.07580252659149173 and parameters: {'metric': 'rmse', 'lambda_l1': 0.011570028878783669, 'lambda_l2': 0.012133515622026487, 'num_leaves': 138, 'feature_fraction': 0.7481792184026679, 'bagging_fraction': 0.6827740473938392, 'bagging_freq': 3, 'min_child_samples': 59}. Best is trial 6 with value: 0.0900992623831805.\n",
      "[I 2025-07-09 23:11:38,013] Trial 17 finished with value: 0.09695012442216087 and parameters: {'metric': 'rmse', 'lambda_l1': 2.942036647802213e-05, 'lambda_l2': 1.5422141311289926e-05, 'num_leaves': 102, 'feature_fraction': 0.6287185430267249, 'bagging_fraction': 0.8612431965755513, 'bagging_freq': 1, 'min_child_samples': 35}. Best is trial 17 with value: 0.09695012442216087.\n",
      "[I 2025-07-09 23:11:45,088] Trial 18 finished with value: 0.07796186440442297 and parameters: {'metric': 'l1', 'lambda_l1': 1.078178008749058e-05, 'lambda_l2': 1.1269837277987956e-05, 'num_leaves': 93, 'feature_fraction': 0.5220881384777858, 'bagging_fraction': 0.899503253960628, 'bagging_freq': 4, 'min_child_samples': 34}. Best is trial 17 with value: 0.09695012442216087.\n",
      "[I 2025-07-09 23:11:48,369] Trial 19 finished with value: 0.08715416659736391 and parameters: {'metric': 'l2', 'lambda_l1': 1.1876675649869911e-07, 'lambda_l2': 3.567847595403264e-07, 'num_leaves': 44, 'feature_fraction': 0.4047448598376914, 'bagging_fraction': 0.8472640655368098, 'bagging_freq': 7, 'min_child_samples': 49}. Best is trial 17 with value: 0.09695012442216087.\n",
      "[I 2025-07-09 23:12:00,619] Trial 20 finished with value: 0.07889448691922428 and parameters: {'metric': 'l1', 'lambda_l1': 0.00367090046285075, 'lambda_l2': 4.610955162407445e-05, 'num_leaves': 117, 'feature_fraction': 0.9822109698968984, 'bagging_fraction': 0.97863567368713, 'bagging_freq': 5, 'min_child_samples': 40}. Best is trial 17 with value: 0.09695012442216087.\n",
      "[I 2025-07-09 23:12:04,927] Trial 21 finished with value: 0.08323141264388717 and parameters: {'metric': 'l2', 'lambda_l1': 1.392161530921474e-07, 'lambda_l2': 1.3644958211913458e-06, 'num_leaves': 41, 'feature_fraction': 0.40883541391975164, 'bagging_fraction': 0.8533755896501237, 'bagging_freq': 7, 'min_child_samples': 53}. Best is trial 17 with value: 0.09695012442216087.\n",
      "[I 2025-07-09 23:12:07,772] Trial 22 finished with value: 0.10212922646659603 and parameters: {'metric': 'l2', 'lambda_l1': 6.593121313662084e-08, 'lambda_l2': 3.868311584739688e-07, 'num_leaves': 39, 'feature_fraction': 0.43619323070759863, 'bagging_fraction': 0.7615450577227199, 'bagging_freq': 6, 'min_child_samples': 49}. Best is trial 22 with value: 0.10212922646659603.\n",
      "[I 2025-07-09 23:12:14,014] Trial 23 finished with value: 0.08037506725937299 and parameters: {'metric': 'l2', 'lambda_l1': 3.996147018951538e-08, 'lambda_l2': 4.118308918340825e-06, 'num_leaves': 93, 'feature_fraction': 0.5302846145738738, 'bagging_fraction': 0.743279163731428, 'bagging_freq': 6, 'min_child_samples': 72}. Best is trial 22 with value: 0.10212922646659603.\n",
      "[I 2025-07-09 23:12:18,053] Trial 24 finished with value: 0.0774456287538648 and parameters: {'metric': 'l2', 'lambda_l1': 1.0805964339986376e-06, 'lambda_l2': 4.070190285064852e-07, 'num_leaves': 31, 'feature_fraction': 0.6061499715935976, 'bagging_fraction': 0.9066720470037881, 'bagging_freq': 5, 'min_child_samples': 58}. Best is trial 22 with value: 0.10212922646659603.\n",
      "[I 2025-07-09 23:12:22,514] Trial 25 finished with value: 0.08972370282703153 and parameters: {'metric': 'l2', 'lambda_l1': 6.241529453501368e-06, 'lambda_l2': 1.678493185555577e-08, 'num_leaves': 68, 'feature_fraction': 0.4728747337119612, 'bagging_fraction': 0.7383830615841713, 'bagging_freq': 6, 'min_child_samples': 31}. Best is trial 22 with value: 0.10212922646659603.\n",
      "[I 2025-07-09 23:12:24,800] Trial 26 finished with value: 0.05786300533736924 and parameters: {'metric': 'rmse', 'lambda_l1': 7.349111693341941, 'lambda_l2': 4.424881797717507e-05, 'num_leaves': 4, 'feature_fraction': 0.690413462642687, 'bagging_fraction': 0.7935749157856098, 'bagging_freq': 4, 'min_child_samples': 43}. Best is trial 22 with value: 0.10212922646659603.\n",
      "[I 2025-07-09 23:12:32,954] Trial 27 finished with value: 0.07626836573125133 and parameters: {'metric': 'l2', 'lambda_l1': 1.6803624045938695e-07, 'lambda_l2': 1.4963034200836243e-07, 'num_leaves': 111, 'feature_fraction': 0.5126842566369851, 'bagging_fraction': 0.5620014649253556, 'bagging_freq': 3, 'min_child_samples': 55}. Best is trial 22 with value: 0.10212922646659603.\n",
      "[I 2025-07-09 23:12:45,459] Trial 28 finished with value: 0.08530026867055299 and parameters: {'metric': 'l1', 'lambda_l1': 3.439765996987368e-08, 'lambda_l2': 3.729093690791452e-06, 'num_leaves': 156, 'feature_fraction': 0.4413151792838953, 'bagging_fraction': 0.8520091696319798, 'bagging_freq': 2, 'min_child_samples': 36}. Best is trial 22 with value: 0.10212922646659603.\n",
      "[I 2025-07-09 23:12:59,825] Trial 29 finished with value: 0.06407398536339665 and parameters: {'metric': 'rmse', 'lambda_l1': 0.00018369604007934358, 'lambda_l2': 0.0004970666462831429, 'num_leaves': 213, 'feature_fraction': 0.7588378221209555, 'bagging_fraction': 0.9432419066308434, 'bagging_freq': 5, 'min_child_samples': 42}. Best is trial 22 with value: 0.10212922646659603.\n",
      "[I 2025-07-09 23:13:08,292] Trial 30 finished with value: 0.08993766529786355 and parameters: {'metric': 'l2', 'lambda_l1': 2.7996981795229636e-06, 'lambda_l2': 8.881550055661452e-06, 'num_leaves': 84, 'feature_fraction': 0.6677839406843261, 'bagging_fraction': 0.4295163593492635, 'bagging_freq': 4, 'min_child_samples': 28}. Best is trial 22 with value: 0.10212922646659603.\n",
      "[I 2025-07-09 23:13:14,400] Trial 31 finished with value: 0.07487525185176606 and parameters: {'metric': 'l2', 'lambda_l1': 3.7807158007301638e-06, 'lambda_l2': 0.00013776332267117746, 'num_leaves': 86, 'feature_fraction': 0.6639417349153798, 'bagging_fraction': 0.5258216211513691, 'bagging_freq': 4, 'min_child_samples': 28}. Best is trial 22 with value: 0.10212922646659603.\n",
      "[I 2025-07-09 23:13:18,276] Trial 32 finished with value: 0.07077462371836664 and parameters: {'metric': 'l2', 'lambda_l1': 5.736028264383936e-07, 'lambda_l2': 6.638618163560965e-06, 'num_leaves': 54, 'feature_fraction': 0.5804963744041938, 'bagging_fraction': 0.4115924628931557, 'bagging_freq': 3, 'min_child_samples': 47}. Best is trial 22 with value: 0.10212922646659603.\n",
      "[I 2025-07-09 23:13:25,479] Trial 33 finished with value: 0.08782612762525331 and parameters: {'metric': 'l2', 'lambda_l1': 3.877252944782655e-05, 'lambda_l2': 1.2545515327646109e-06, 'num_leaves': 122, 'feature_fraction': 0.8103118324665041, 'bagging_fraction': 0.4488175315776861, 'bagging_freq': 4, 'min_child_samples': 13}. Best is trial 22 with value: 0.10212922646659603.\n",
      "[I 2025-07-09 23:13:31,123] Trial 34 finished with value: 0.07325213889386065 and parameters: {'metric': 'l2', 'lambda_l1': 2.6364030003693125e-06, 'lambda_l2': 8.667192527900406e-05, 'num_leaves': 79, 'feature_fraction': 0.6001990298197821, 'bagging_fraction': 0.790906551250022, 'bagging_freq': 1, 'min_child_samples': 47}. Best is trial 22 with value: 0.10212922646659603.\n",
      "[I 2025-07-09 23:13:40,762] Trial 35 finished with value: 0.09456788938375403 and parameters: {'metric': 'l2', 'lambda_l1': 2.964891277633065e-07, 'lambda_l2': 3.2918757563345363e-07, 'num_leaves': 107, 'feature_fraction': 0.7236638119029362, 'bagging_fraction': 0.6567006414583215, 'bagging_freq': 3, 'min_child_samples': 19}. Best is trial 22 with value: 0.10212922646659603.\n",
      "[I 2025-07-09 23:13:50,775] Trial 36 finished with value: 0.0833913253080491 and parameters: {'metric': 'l1', 'lambda_l1': 2.9681950816970085e-08, 'lambda_l2': 1.1022334085879895e-07, 'num_leaves': 155, 'feature_fraction': 0.873966112784363, 'bagging_fraction': 0.6773898817971542, 'bagging_freq': 2, 'min_child_samples': 18}. Best is trial 22 with value: 0.10212922646659603.\n",
      "[I 2025-07-09 23:14:07,217] Trial 37 finished with value: 0.07588852172133687 and parameters: {'metric': 'l2', 'lambda_l1': 3.815293522476185e-07, 'lambda_l2': 3.803760850247445e-08, 'num_leaves': 108, 'feature_fraction': 0.7251565139540771, 'bagging_fraction': 0.6425700725774752, 'bagging_freq': 1, 'min_child_samples': 20}. Best is trial 22 with value: 0.10212922646659603.\n",
      "[I 2025-07-09 23:14:17,616] Trial 38 finished with value: 0.07785609674664 and parameters: {'metric': 'l1', 'lambda_l1': 0.0008018918175233049, 'lambda_l2': 4.05484334262198e-07, 'num_leaves': 185, 'feature_fraction': 0.7811300808531519, 'bagging_fraction': 0.7151742161809715, 'bagging_freq': 3, 'min_child_samples': 11}. Best is trial 22 with value: 0.10212922646659603.\n",
      "[I 2025-07-09 23:14:25,076] Trial 39 finished with value: 0.07191506166233264 and parameters: {'metric': 'rmse', 'lambda_l1': 6.64657675588887e-08, 'lambda_l2': 1.4482469123115426e-06, 'num_leaves': 126, 'feature_fraction': 0.7204469974176027, 'bagging_fraction': 0.5792901934916369, 'bagging_freq': 2, 'min_child_samples': 38}. Best is trial 22 with value: 0.10212922646659603.\n",
      "[I 2025-07-09 23:14:30,962] Trial 40 finished with value: 0.09083974959202124 and parameters: {'metric': 'l1', 'lambda_l1': 1.3933191931753399e-08, 'lambda_l2': 0.07561302530036963, 'num_leaves': 160, 'feature_fraction': 0.4403721030298328, 'bagging_fraction': 0.6616637388482107, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 22 with value: 0.10212922646659603.\n",
      "[I 2025-07-09 23:14:38,970] Trial 41 finished with value: 0.08513468467136334 and parameters: {'metric': 'l1', 'lambda_l1': 1.0176463591502167e-08, 'lambda_l2': 0.1345367197449348, 'num_leaves': 161, 'feature_fraction': 0.4535145992272063, 'bagging_fraction': 0.6651945859437137, 'bagging_freq': 2, 'min_child_samples': 15}. Best is trial 22 with value: 0.10212922646659603.\n",
      "[I 2025-07-09 23:14:48,056] Trial 42 finished with value: 0.08228913521022743 and parameters: {'metric': 'l1', 'lambda_l1': 2.414893816160339e-07, 'lambda_l2': 1.008564756895315, 'num_leaves': 141, 'feature_fraction': 0.5005187606816388, 'bagging_fraction': 0.7674196162893309, 'bagging_freq': 1, 'min_child_samples': 5}. Best is trial 22 with value: 0.10212922646659603.\n",
      "[I 2025-07-09 23:14:55,353] Trial 43 finished with value: 0.07900255260929162 and parameters: {'metric': 'l1', 'lambda_l1': 2.7562661879266192e-08, 'lambda_l2': 9.149335752920539, 'num_leaves': 170, 'feature_fraction': 0.5430206141615012, 'bagging_fraction': 0.7085927196307951, 'bagging_freq': 2, 'min_child_samples': 10}. Best is trial 22 with value: 0.10212922646659603.\n",
      "[I 2025-07-09 23:14:59,570] Trial 44 finished with value: 0.07992373341868209 and parameters: {'metric': 'l1', 'lambda_l1': 8.626641007105142e-08, 'lambda_l2': 0.03030652309645176, 'num_leaves': 98, 'feature_fraction': 0.43282196371551684, 'bagging_fraction': 0.635104307485223, 'bagging_freq': 1, 'min_child_samples': 22}. Best is trial 22 with value: 0.10212922646659603.\n",
      "[I 2025-07-09 23:15:07,604] Trial 45 finished with value: 0.08540629698543872 and parameters: {'metric': 'l1', 'lambda_l1': 9.352652758575538e-07, 'lambda_l2': 0.0020788950194312174, 'num_leaves': 131, 'feature_fraction': 0.48194428038046094, 'bagging_fraction': 0.5993396055977077, 'bagging_freq': 3, 'min_child_samples': 89}. Best is trial 22 with value: 0.10212922646659603.\n",
      "[I 2025-07-09 23:15:22,545] Trial 46 finished with value: 0.0958602183808282 and parameters: {'metric': 'rmse', 'lambda_l1': 1.84266026037822e-08, 'lambda_l2': 0.3035646300979559, 'num_leaves': 188, 'feature_fraction': 0.43121111102309206, 'bagging_fraction': 0.7468934320904639, 'bagging_freq': 2, 'min_child_samples': 9}. Best is trial 22 with value: 0.10212922646659603.\n",
      "[I 2025-07-09 23:16:03,998] Trial 47 finished with value: 0.08241087629713972 and parameters: {'metric': 'rmse', 'lambda_l1': 0.193600369882016, 'lambda_l2': 0.19106465061692615, 'num_leaves': 207, 'feature_fraction': 0.8832293473377301, 'bagging_fraction': 0.8158859430255466, 'bagging_freq': 2, 'min_child_samples': 9}. Best is trial 22 with value: 0.10212922646659603.\n",
      "[I 2025-07-09 23:16:15,550] Trial 48 finished with value: 0.06634848714795583 and parameters: {'metric': 'rmse', 'lambda_l1': 1.4064870844370412e-08, 'lambda_l2': 0.05955396019614954, 'num_leaves': 191, 'feature_fraction': 0.4262380175856145, 'bagging_fraction': 0.7377030814019921, 'bagging_freq': 1, 'min_child_samples': 16}. Best is trial 22 with value: 0.10212922646659603.\n",
      "[I 2025-07-09 23:18:01,885] Trial 49 finished with value: 0.07899615407603565 and parameters: {'metric': 'rmse', 'lambda_l1': 8.428284460002865e-08, 'lambda_l2': 0.42365993423072057, 'num_leaves': 147, 'feature_fraction': 0.8552762315331452, 'bagging_fraction': 0.7747220449051625, 'bagging_freq': 2, 'min_child_samples': 7}. Best is trial 22 with value: 0.10212922646659603.\n",
      "[I 2025-07-09 23:20:08,124] Trial 50 finished with value: 0.08336382023365531 and parameters: {'metric': 'rmse', 'lambda_l1': 1.2369597469130647e-06, 'lambda_l2': 0.005790905228406493, 'num_leaves': 231, 'feature_fraction': 0.47905711754286706, 'bagging_fraction': 0.6907646052641562, 'bagging_freq': 2, 'min_child_samples': 27}. Best is trial 22 with value: 0.10212922646659603.\n",
      "[I 2025-07-09 23:22:13,192] Trial 51 finished with value: 0.08925496616186866 and parameters: {'metric': 'rmse', 'lambda_l1': 4.2617759486134785e-08, 'lambda_l2': 1.3491708241899385, 'num_leaves': 181, 'feature_fraction': 0.46082534486926824, 'bagging_fraction': 0.7242147082473349, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 22 with value: 0.10212922646659603.\n",
      "[I 2025-07-09 23:23:13,362] Trial 52 finished with value: 0.0845293817861537 and parameters: {'metric': 'l1', 'lambda_l1': 1.8146929200529363e-08, 'lambda_l2': 0.4303716639699453, 'num_leaves': 201, 'feature_fraction': 0.5500536738438672, 'bagging_fraction': 0.6580466089436727, 'bagging_freq': 3, 'min_child_samples': 62}. Best is trial 22 with value: 0.10212922646659603.\n",
      "[I 2025-07-09 23:23:18,490] Trial 53 finished with value: 0.09291892652575501 and parameters: {'metric': 'rmse', 'lambda_l1': 2.878301569516896e-07, 'lambda_l2': 3.6283605345788277, 'num_leaves': 66, 'feature_fraction': 0.42748118049561373, 'bagging_fraction': 0.606694700757138, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 22 with value: 0.10212922646659603.\n",
      "[I 2025-07-09 23:23:21,315] Trial 54 finished with value: 0.07746453111345428 and parameters: {'metric': 'rmse', 'lambda_l1': 2.56158202623731e-07, 'lambda_l2': 1.623948664280683, 'num_leaves': 23, 'feature_fraction': 0.42509250377449986, 'bagging_fraction': 0.6058953853144445, 'bagging_freq': 1, 'min_child_samples': 5}. Best is trial 22 with value: 0.10212922646659603.\n",
      "[I 2025-07-09 23:23:26,225] Trial 55 finished with value: 0.09306845926488758 and parameters: {'metric': 'rmse', 'lambda_l1': 1.3272776697344747e-05, 'lambda_l2': 2.3813891180969233, 'num_leaves': 65, 'feature_fraction': 0.40383126025195093, 'bagging_fraction': 0.5630740870347518, 'bagging_freq': 3, 'min_child_samples': 18}. Best is trial 22 with value: 0.10212922646659603.\n",
      "[I 2025-07-09 23:23:33,447] Trial 56 finished with value: 0.08586025068699414 and parameters: {'metric': 'rmse', 'lambda_l1': 1.7028911403949693e-05, 'lambda_l2': 3.998499003009296, 'num_leaves': 58, 'feature_fraction': 0.4041991410684154, 'bagging_fraction': 0.48325100807646315, 'bagging_freq': 3, 'min_child_samples': 19}. Best is trial 22 with value: 0.10212922646659603.\n",
      "[I 2025-07-09 23:23:39,228] Trial 57 finished with value: 0.08827018823372715 and parameters: {'metric': 'rmse', 'lambda_l1': 9.254418346279385e-05, 'lambda_l2': 2.966645853792315, 'num_leaves': 38, 'feature_fraction': 0.5007734042095886, 'bagging_fraction': 0.5495650845797072, 'bagging_freq': 3, 'min_child_samples': 23}. Best is trial 22 with value: 0.10212922646659603.\n",
      "[I 2025-07-09 23:23:50,153] Trial 58 finished with value: 0.08649177720639217 and parameters: {'metric': 'rmse', 'lambda_l1': 5.302344811074507e-05, 'lambda_l2': 9.224833269610413, 'num_leaves': 54, 'feature_fraction': 0.6599036162090702, 'bagging_fraction': 0.8754597257169436, 'bagging_freq': 3, 'min_child_samples': 32}. Best is trial 22 with value: 0.10212922646659603.\n",
      "[I 2025-07-09 23:23:56,336] Trial 59 finished with value: 0.09538197806718184 and parameters: {'metric': 'rmse', 'lambda_l1': 9.03615870385942e-06, 'lambda_l2': 2.323289733877282e-07, 'num_leaves': 66, 'feature_fraction': 0.4558464012592315, 'bagging_fraction': 0.5740601608838971, 'bagging_freq': 4, 'min_child_samples': 14}. Best is trial 22 with value: 0.10212922646659603.\n",
      "[I 2025-07-09 23:24:01,489] Trial 60 finished with value: 0.07921601668465005 and parameters: {'metric': 'rmse', 'lambda_l1': 0.0005015327159263585, 'lambda_l2': 1.3840030142628251e-08, 'num_leaves': 24, 'feature_fraction': 0.7091996154764366, 'bagging_fraction': 0.4786619176887347, 'bagging_freq': 5, 'min_child_samples': 16}. Best is trial 22 with value: 0.10212922646659603.\n",
      "[I 2025-07-09 23:24:06,753] Trial 61 finished with value: 0.09448365010045758 and parameters: {'metric': 'rmse', 'lambda_l1': 8.73839718101701e-06, 'lambda_l2': 7.317546032963144e-07, 'num_leaves': 72, 'feature_fraction': 0.4525758837597535, 'bagging_fraction': 0.5808072039418538, 'bagging_freq': 4, 'min_child_samples': 13}. Best is trial 22 with value: 0.10212922646659603.\n",
      "[I 2025-07-09 23:24:13,805] Trial 62 finished with value: 0.10583593225687359 and parameters: {'metric': 'rmse', 'lambda_l1': 7.828002649331311e-06, 'lambda_l2': 2.497724573187604e-07, 'num_leaves': 75, 'feature_fraction': 0.45411258929581977, 'bagging_fraction': 0.575905283009444, 'bagging_freq': 4, 'min_child_samples': 13}. Best is trial 62 with value: 0.10583593225687359.\n",
      "[I 2025-07-09 23:24:23,280] Trial 63 finished with value: 0.08334622962882657 and parameters: {'metric': 'rmse', 'lambda_l1': 0.000197104375728516, 'lambda_l2': 1.8802495766355086e-07, 'num_leaves': 102, 'feature_fraction': 0.4478165315573168, 'bagging_fraction': 0.8143727475507496, 'bagging_freq': 4, 'min_child_samples': 14}. Best is trial 62 with value: 0.10583593225687359.\n",
      "[I 2025-07-09 23:24:55,174] Trial 64 finished with value: 0.08562087984118599 and parameters: {'metric': 'rmse', 'lambda_l1': 7.859166547371789e-06, 'lambda_l2': 7.765166389011168e-07, 'num_leaves': 73, 'feature_fraction': 0.4686228442983455, 'bagging_fraction': 0.5841454360061648, 'bagging_freq': 5, 'min_child_samples': 10}. Best is trial 62 with value: 0.10583593225687359.\n",
      "[I 2025-07-09 23:25:47,393] Trial 65 finished with value: 0.08343014241690538 and parameters: {'metric': 'rmse', 'lambda_l1': 2.3342140434233535e-05, 'lambda_l2': 4.3294706457472526e-08, 'num_leaves': 89, 'feature_fraction': 0.5265221760012804, 'bagging_fraction': 0.5070915578147391, 'bagging_freq': 4, 'min_child_samples': 25}. Best is trial 62 with value: 0.10583593225687359.\n",
      "[I 2025-07-09 23:26:53,343] Trial 66 finished with value: 0.08177016877508544 and parameters: {'metric': 'l2', 'lambda_l1': 4.307347640404768e-06, 'lambda_l2': 2.3761153285406413e-06, 'num_leaves': 103, 'feature_fraction': 0.49910743734840646, 'bagging_fraction': 0.6242340999896556, 'bagging_freq': 4, 'min_child_samples': 21}. Best is trial 62 with value: 0.10583593225687359.\n",
      "[I 2025-07-09 23:27:33,582] Trial 67 finished with value: 0.09466370172177362 and parameters: {'metric': 'rmse', 'lambda_l1': 1.759713987604683e-06, 'lambda_l2': 6.876366668481458e-08, 'num_leaves': 49, 'feature_fraction': 0.5748759095979594, 'bagging_fraction': 0.540275253986171, 'bagging_freq': 4, 'min_child_samples': 12}. Best is trial 62 with value: 0.10583593225687359.\n",
      "[I 2025-07-09 23:28:06,239] Trial 68 finished with value: 0.08325873078754947 and parameters: {'metric': 'l2', 'lambda_l1': 2.2086412411212175e-06, 'lambda_l2': 7.131393524495305e-08, 'num_leaves': 48, 'feature_fraction': 0.6067766512606995, 'bagging_fraction': 0.5254094974721517, 'bagging_freq': 5, 'min_child_samples': 9}. Best is trial 62 with value: 0.10583593225687359.\n",
      "[I 2025-07-09 23:28:24,979] Trial 69 finished with value: 0.0841130674441686 and parameters: {'metric': 'rmse', 'lambda_l1': 6.696064876715952e-07, 'lambda_l2': 2.3266804951165427e-07, 'num_leaves': 16, 'feature_fraction': 0.6296034754587929, 'bagging_fraction': 0.7488080480809772, 'bagging_freq': 6, 'min_child_samples': 31}. Best is trial 62 with value: 0.10583593225687359.\n",
      "[I 2025-07-09 23:29:00,461] Trial 70 finished with value: 0.0774851151187858 and parameters: {'metric': 'l2', 'lambda_l1': 1.5825025616908966e-06, 'lambda_l2': 1.7771327354516554e-05, 'num_leaves': 80, 'feature_fraction': 0.6560611738902119, 'bagging_fraction': 0.5469683600566297, 'bagging_freq': 4, 'min_child_samples': 26}. Best is trial 62 with value: 0.10583593225687359.\n",
      "[I 2025-07-09 23:29:07,471] Trial 71 finished with value: 0.09718854462396538 and parameters: {'metric': 'rmse', 'lambda_l1': 8.64294595774719e-06, 'lambda_l2': 9.99663859578806e-08, 'num_leaves': 35, 'feature_fraction': 0.567861506670192, 'bagging_fraction': 0.5775188167571264, 'bagging_freq': 4, 'min_child_samples': 14}. Best is trial 62 with value: 0.10583593225687359.\n",
      "[I 2025-07-09 23:29:12,327] Trial 72 finished with value: 0.08890394594423517 and parameters: {'metric': 'rmse', 'lambda_l1': 2.9749903693252475e-05, 'lambda_l2': 1.3385359669534885e-07, 'num_leaves': 39, 'feature_fraction': 0.5808765826753046, 'bagging_fraction': 0.5017759747928026, 'bagging_freq': 4, 'min_child_samples': 12}. Best is trial 62 with value: 0.10583593225687359.\n",
      "[I 2025-07-09 23:29:16,372] Trial 73 finished with value: 0.07263013818700023 and parameters: {'metric': 'rmse', 'lambda_l1': 7.926253588368487e-05, 'lambda_l2': 2.4939775771195114e-08, 'num_leaves': 14, 'feature_fraction': 0.6779917231530088, 'bagging_fraction': 0.9558878677276905, 'bagging_freq': 4, 'min_child_samples': 19}. Best is trial 62 with value: 0.10583593225687359.\n",
      "[I 2025-07-09 23:29:23,437] Trial 74 finished with value: 0.06874654632562843 and parameters: {'metric': 'rmse', 'lambda_l1': 5.293572948456171e-06, 'lambda_l2': 6.924678786223987e-08, 'num_leaves': 50, 'feature_fraction': 0.5602814778672719, 'bagging_fraction': 0.5404075195230837, 'bagging_freq': 5, 'min_child_samples': 8}. Best is trial 62 with value: 0.10583593225687359.\n",
      "[I 2025-07-09 23:29:42,481] Trial 75 finished with value: 0.08453704206423783 and parameters: {'metric': 'rmse', 'lambda_l1': 5.506030393224139e-07, 'lambda_l2': 1.0651607990653202e-08, 'num_leaves': 33, 'feature_fraction': 0.5866015160003079, 'bagging_fraction': 0.8364795598232799, 'bagging_freq': 4, 'min_child_samples': 36}. Best is trial 62 with value: 0.10583593225687359.\n",
      "[I 2025-07-09 23:29:59,835] Trial 76 finished with value: 0.09664460136267729 and parameters: {'metric': 'l2', 'lambda_l1': 1.23988502513367e-05, 'lambda_l2': 6.381280134618316e-07, 'num_leaves': 28, 'feature_fraction': 0.6133322667194967, 'bagging_fraction': 0.5649483176413308, 'bagging_freq': 4, 'min_child_samples': 75}. Best is trial 62 with value: 0.10583593225687359.\n",
      "[I 2025-07-09 23:30:17,490] Trial 77 finished with value: 0.08304246300468536 and parameters: {'metric': 'rmse', 'lambda_l1': 0.002306001099281055, 'lambda_l2': 3.8420361807063325e-06, 'num_leaves': 30, 'feature_fraction': 0.6410059876856946, 'bagging_fraction': 0.5584272337116666, 'bagging_freq': 7, 'min_child_samples': 67}. Best is trial 62 with value: 0.10583593225687359.\n",
      "[I 2025-07-09 23:30:23,058] Trial 78 finished with value: 0.06596574987989762 and parameters: {'metric': 'rmse', 'lambda_l1': 5.203609726402199e-05, 'lambda_l2': 6.520740738932117e-07, 'num_leaves': 4, 'feature_fraction': 0.5421824904596141, 'bagging_fraction': 0.4580769829756278, 'bagging_freq': 6, 'min_child_samples': 78}. Best is trial 62 with value: 0.10583593225687359.\n",
      "[I 2025-07-09 23:31:17,711] Trial 79 finished with value: 0.09560139231556854 and parameters: {'metric': 'l2', 'lambda_l1': 1.3474918048675302e-05, 'lambda_l2': 9.632052163840556e-08, 'num_leaves': 62, 'feature_fraction': 0.6206309603250001, 'bagging_fraction': 0.5702058836432743, 'bagging_freq': 4, 'min_child_samples': 98}. Best is trial 62 with value: 0.10583593225687359.\n",
      "[I 2025-07-09 23:32:06,539] Trial 80 finished with value: 0.09112211085588048 and parameters: {'metric': 'l2', 'lambda_l1': 0.00015256136110147975, 'lambda_l2': 2.1980072037590376e-06, 'num_leaves': 61, 'feature_fraction': 0.614324825138723, 'bagging_fraction': 0.5713190211008596, 'bagging_freq': 5, 'min_child_samples': 93}. Best is trial 62 with value: 0.10583593225687359.\n",
      "[I 2025-07-09 23:32:20,877] Trial 81 finished with value: 0.09384176335966132 and parameters: {'metric': 'l2', 'lambda_l1': 1.7610139304278188e-05, 'lambda_l2': 7.458142980150246e-08, 'num_leaves': 46, 'feature_fraction': 0.64411699620475, 'bagging_fraction': 0.5903195084222355, 'bagging_freq': 4, 'min_child_samples': 75}. Best is trial 62 with value: 0.10583593225687359.\n",
      "[I 2025-07-09 23:32:24,585] Trial 82 finished with value: 0.09706582134346836 and parameters: {'metric': 'l2', 'lambda_l1': 5.073322644529174e-06, 'lambda_l2': 2.7009949214855408e-08, 'num_leaves': 11, 'feature_fraction': 0.5935030413117525, 'bagging_fraction': 0.5227951847860183, 'bagging_freq': 4, 'min_child_samples': 56}. Best is trial 62 with value: 0.10583593225687359.\n",
      "[I 2025-07-09 23:32:28,869] Trial 83 finished with value: 0.09717123521375051 and parameters: {'metric': 'l2', 'lambda_l1': 1.1480521548445978e-05, 'lambda_l2': 2.95120355689213e-08, 'num_leaves': 11, 'feature_fraction': 0.594764971662892, 'bagging_fraction': 0.5195240612321873, 'bagging_freq': 4, 'min_child_samples': 84}. Best is trial 62 with value: 0.10583593225687359.\n",
      "[I 2025-07-09 23:32:32,765] Trial 84 finished with value: 0.08174368002908573 and parameters: {'metric': 'l2', 'lambda_l1': 3.2939244546132534e-06, 'lambda_l2': 2.182190679683012e-08, 'num_leaves': 13, 'feature_fraction': 0.5964759921584231, 'bagging_fraction': 0.5207350335241328, 'bagging_freq': 4, 'min_child_samples': 87}. Best is trial 62 with value: 0.10583593225687359.\n",
      "[I 2025-07-09 23:32:37,096] Trial 85 finished with value: 0.0995834081473038 and parameters: {'metric': 'l2', 'lambda_l1': 2.5371961517352583e-05, 'lambda_l2': 2.9685354503530737e-08, 'num_leaves': 28, 'feature_fraction': 0.5671675838018919, 'bagging_fraction': 0.47788997306424774, 'bagging_freq': 4, 'min_child_samples': 99}. Best is trial 62 with value: 0.10583593225687359.\n",
      "[I 2025-07-09 23:32:40,582] Trial 86 finished with value: 0.053143922324420126 and parameters: {'metric': 'l2', 'lambda_l1': 3.0879430289491064e-05, 'lambda_l2': 3.0382902523902176e-08, 'num_leaves': 2, 'feature_fraction': 0.5948108559264719, 'bagging_fraction': 0.494882184737692, 'bagging_freq': 5, 'min_child_samples': 84}. Best is trial 62 with value: 0.10583593225687359.\n",
      "[I 2025-07-09 23:32:43,394] Trial 87 finished with value: 0.09329823812891878 and parameters: {'metric': 'l2', 'lambda_l1': 0.0004536998390898853, 'lambda_l2': 4.5663031143429085e-08, 'num_leaves': 12, 'feature_fraction': 0.55813842502027, 'bagging_fraction': 0.4552333124201252, 'bagging_freq': 4, 'min_child_samples': 72}. Best is trial 62 with value: 0.10583593225687359.\n",
      "[I 2025-07-09 23:32:47,255] Trial 88 finished with value: 0.07005706130511226 and parameters: {'metric': 'l2', 'lambda_l1': 0.00012722325869527195, 'lambda_l2': 1.7120253371593673e-08, 'num_leaves': 30, 'feature_fraction': 0.5691237598363323, 'bagging_fraction': 0.4816795338455171, 'bagging_freq': 5, 'min_child_samples': 56}. Best is trial 62 with value: 0.10583593225687359.\n",
      "[I 2025-07-09 23:32:55,625] Trial 89 finished with value: 0.09108477852153937 and parameters: {'metric': 'l2', 'lambda_l1': 5.5820212755618135e-06, 'lambda_l2': 4.020248594047078e-07, 'num_leaves': 23, 'feature_fraction': 0.5346611882465301, 'bagging_fraction': 0.44079136168530464, 'bagging_freq': 4, 'min_child_samples': 51}. Best is trial 62 with value: 0.10583593225687359.\n",
      "[I 2025-07-09 23:33:02,172] Trial 90 finished with value: 0.08067733557988875 and parameters: {'metric': 'l2', 'lambda_l1': 6.29639368000623e-05, 'lambda_l2': 1.5818977104996788e-07, 'num_leaves': 7, 'feature_fraction': 0.6934989411045617, 'bagging_fraction': 0.4720928334328356, 'bagging_freq': 5, 'min_child_samples': 81}. Best is trial 62 with value: 0.10583593225687359.\n",
      "[I 2025-07-09 23:33:22,837] Trial 91 finished with value: 0.08877987187168983 and parameters: {'metric': 'l2', 'lambda_l1': 1.1672760991104014e-05, 'lambda_l2': 1.1165768615400502e-07, 'num_leaves': 35, 'feature_fraction': 0.6250234329954756, 'bagging_fraction': 0.5301502093431059, 'bagging_freq': 4, 'min_child_samples': 98}. Best is trial 62 with value: 0.10583593225687359.\n",
      "[I 2025-07-09 23:33:25,914] Trial 92 finished with value: 0.08672850232533379 and parameters: {'metric': 'l2', 'lambda_l1': 1.672760953666303e-05, 'lambda_l2': 1.0016291705940999e-08, 'num_leaves': 25, 'feature_fraction': 0.5147204532977521, 'bagging_fraction': 0.512076884472074, 'bagging_freq': 4, 'min_child_samples': 92}. Best is trial 62 with value: 0.10583593225687359.\n",
      "[I 2025-07-09 23:33:28,857] Trial 93 finished with value: 0.09288901645233903 and parameters: {'metric': 'l2', 'lambda_l1': 6.606218071118009e-06, 'lambda_l2': 3.5598464097783126e-08, 'num_leaves': 9, 'feature_fraction': 0.6128131427506123, 'bagging_fraction': 0.9212137110146532, 'bagging_freq': 4, 'min_child_samples': 95}. Best is trial 62 with value: 0.10583593225687359.\n",
      "[I 2025-07-09 23:33:39,773] Trial 94 finished with value: 0.07957398788402377 and parameters: {'metric': 'l2', 'lambda_l1': 0.00030556591438623827, 'lambda_l2': 9.731721393388126e-08, 'num_leaves': 17, 'feature_fraction': 0.6526221909863235, 'bagging_fraction': 0.799746412023967, 'bagging_freq': 4, 'min_child_samples': 97}. Best is trial 62 with value: 0.10583593225687359.\n",
      "[I 2025-07-09 23:34:17,038] Trial 95 finished with value: 0.07440950886204703 and parameters: {'metric': 'l2', 'lambda_l1': 2.968741494618074e-05, 'lambda_l2': 2.5882487547624564e-07, 'num_leaves': 42, 'feature_fraction': 0.622356329600867, 'bagging_fraction': 0.99966681359197, 'bagging_freq': 1, 'min_child_samples': 100}. Best is trial 62 with value: 0.10583593225687359.\n",
      "[I 2025-07-09 23:34:46,657] Trial 96 finished with value: 0.0842595691238387 and parameters: {'metric': 'l2', 'lambda_l1': 3.1942011081588153e-06, 'lambda_l2': 5.678100389767351e-07, 'num_leaves': 27, 'feature_fraction': 0.6783373454797377, 'bagging_fraction': 0.6184303833735216, 'bagging_freq': 4, 'min_child_samples': 61}. Best is trial 62 with value: 0.10583593225687359.\n",
      "[I 2025-07-09 23:35:08,585] Trial 97 finished with value: 0.08369984017877324 and parameters: {'metric': 'l2', 'lambda_l1': 2.0067040586576976e-05, 'lambda_l2': 1.1501891310413908e-06, 'num_leaves': 19, 'feature_fraction': 0.41660589435639706, 'bagging_fraction': 0.4955250942013401, 'bagging_freq': 6, 'min_child_samples': 43}. Best is trial 62 with value: 0.10583593225687359.\n",
      "[I 2025-07-09 23:37:17,805] Trial 98 finished with value: 0.0836238543849735 and parameters: {'metric': 'l2', 'lambda_l1': 4.6677971902468045e-05, 'lambda_l2': 1.9761269478150847e-08, 'num_leaves': 245, 'feature_fraction': 0.593680937291056, 'bagging_fraction': 0.7763595154040283, 'bagging_freq': 7, 'min_child_samples': 68}. Best is trial 62 with value: 0.10583593225687359.\n",
      "[I 2025-07-09 23:37:35,929] Trial 99 finished with value: 0.08990487526447473 and parameters: {'metric': 'l2', 'lambda_l1': 0.00010159988810250204, 'lambda_l2': 0.0002939046056233138, 'num_leaves': 116, 'feature_fraction': 0.5700321420367256, 'bagging_fraction': 0.5607765914231359, 'bagging_freq': 3, 'min_child_samples': 91}. Best is trial 62 with value: 0.10583593225687359.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 100\n",
      "Best trial:\n",
      "  Value: 0.10583593225687359\n",
      "  Params: \n",
      "    metric: rmse\n",
      "    lambda_l1: 7.828002649331311e-06\n",
      "    lambda_l2: 2.497724573187604e-07\n",
      "    num_leaves: 75\n",
      "    feature_fraction: 0.45411258929581977\n",
      "    bagging_fraction: 0.575905283009444\n",
      "    bagging_freq: 4\n",
      "    min_child_samples: 13\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation with optimal params\n",
    "# train_X, valid_X, train_y, valid_y = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# # Other splitting method\n",
    "# num_test = int(X.shape[0] * 0.2)\n",
    "# train_X, train_y = X[:-num_test], y[:-num_test]\n",
    "# valid_X, valid_y = X[-num_test:], y[-num_test:]\n",
    "\n",
    "dtrain = lgb.Dataset(X, label=y)\n",
    "\n",
    "params = {\n",
    "  \"objective\": \"regression\",\n",
    "  \"metric\": \"rmse\",\n",
    "  \"verbosity\": -1,\n",
    "  \"boosting_type\": \"gbdt\",\n",
    "  \"lambda_l1\": 7.828002649331311e-06,\n",
    "  \"lambda_l2\": 2.497724573187604e-07,\n",
    "  \"num_leaves\": 75,\n",
    "  \"feature_fraction\": 0.45411258929581977,\n",
    "  \"bagging_fraction\": 0.575905283009444,\n",
    "  \"bagging_freq\": 4,\n",
    "  \"min_child_samples\": 13,\n",
    "}\n",
    "\n",
    "gbm = lgb.train(params, dtrain)\n",
    "# preds = gbm.predict(valid_X)\n",
    "# correlation = pearsonr(preds, valid_y).statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10583593225687357"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pl.read_csv('data/clean/test_pca_170.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/lightgbm/basic.py:1238: UserWarning: Converting data to scipy sparse matrix.\n",
      "  _log_warning(\"Converting data to scipy sparse matrix.\")\n"
     ]
    }
   ],
   "source": [
    "preds = gbm.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pl.DataFrame({\n",
    "  'ID': range(1, len(preds)+1),\n",
    "  'prediction': preds\n",
    "})\n",
    "submission.write_csv('results/optuna.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optuna XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "  num_test = int(X.shape[0] * 0.2)\n",
    "  train_X, train_y = X[:-num_test], y[:-num_test]\n",
    "  valid_X, valid_y = X[-num_test:], y[-num_test:]\n",
    "\n",
    "  dtrain = xgb.DMatrix(train_X, label=train_y)\n",
    "  dvalid = xgb.DMatrix(valid_X, label=valid_y)\n",
    "\n",
    "  params = {\n",
    "    \"tree_method\": \"gpu_hist\",\n",
    "    \"booster\": \"dart\",\n",
    "    \"sampling_method\": \"gradient_based\",\n",
    "    \"n_estimators\": trial.suggest_int('n_estimators', 16, 256),\n",
    "    \"lambda\": trial.suggest_uniform('lambda', 0.01, 1),\n",
    "    'alpha': trial.suggest_uniform('alpha', 0.01, 1),\n",
    "    'eta': trial.suggest_categorical('eta', [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]),\n",
    "    'gamma': trial.suggest_categorical('gamma', [18, 19, 20, 21, 22, 23, 24, 25]),\n",
    "    'learning_rate': trial.suggest_categorical('learning_rate', [0.008,0.01,0.012,0.014,0.016,0.018, 0.02]),\n",
    "    'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3,0.4,0.5,0.6,0.7,0.8,0.9, 1.0]),\n",
    "    'colsample_bynode': trial.suggest_categorical('colsample_bynode', [0.3,0.4,0.5,0.6,0.7,0.8,0.9, 1.0]),\n",
    "    'n_estimators': trial.suggest_int('n_estimators', 400, 1000),\n",
    "    'min_child_weight': trial.suggest_int('min_child_weight', 8, 600),  \n",
    "    'max_depth': trial.suggest_categorical('max_depth', [3, 4, 5, 6, 7]),  \n",
    "    'subsample': trial.suggest_categorical('subsample', [0.5,0.6,0.7,0.8,1.0]),\n",
    "    'random_state': 42\n",
    "  }\n",
    "\n",
    "  model = xgb.train(params, dtrain)\n",
    "  preds = model.predict(dvalid)\n",
    "  correlation = pearsonr(preds, valid_y).statistic\n",
    "  return correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-09 22:20:20,644] A new study created in memory with name: no-name-330aadf2-47cc-41d8-9151-e3601c4b5000\n",
      "/tmp/ipykernel_58075/3574269890.py:14: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"lambda\": trial.suggest_uniform('lambda', 0.01, 1),\n",
      "/tmp/ipykernel_58075/3574269890.py:15: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'alpha': trial.suggest_uniform('alpha', 0.01, 1),\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/optuna/trial/_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"n_estimators\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'log': False, 'step': 1, 'low': 16, 'high': 256}\n",
      "  warnings.warn(\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:21] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:21] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:20:21] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:20:21,764] Trial 0 finished with value: 0.02293350737754938 and parameters: {'n_estimators': 212, 'lambda': 0.8652467178859906, 'alpha': 0.8106355167640886, 'eta': 0.8, 'gamma': 21, 'learning_rate': 0.014, 'colsample_bytree': 0.6, 'colsample_bynode': 1.0, 'min_child_weight': 207, 'max_depth': 7, 'subsample': 0.7}. Best is trial 0 with value: 0.02293350737754938.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:22] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:22] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:20:22] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:20:22,352] Trial 1 finished with value: 0.023870487014792406 and parameters: {'n_estimators': 254, 'lambda': 0.4760970728021651, 'alpha': 0.5455136899904651, 'eta': 0.7, 'gamma': 22, 'learning_rate': 0.016, 'colsample_bytree': 0.5, 'colsample_bynode': 1.0, 'min_child_weight': 261, 'max_depth': 5, 'subsample': 1.0}. Best is trial 1 with value: 0.023870487014792406.\n",
      "[I 2025-07-09 22:20:22,936] Trial 2 finished with value: 0.03390156039753684 and parameters: {'n_estimators': 91, 'lambda': 0.8387128260701858, 'alpha': 0.020769523561620245, 'eta': 0.9, 'gamma': 22, 'learning_rate': 0.02, 'colsample_bytree': 0.8, 'colsample_bynode': 1.0, 'min_child_weight': 507, 'max_depth': 5, 'subsample': 0.8}. Best is trial 2 with value: 0.03390156039753684.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:23] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:23] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:20:23] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:20:23,665] Trial 3 finished with value: 0.04497681219284133 and parameters: {'n_estimators': 86, 'lambda': 0.8944449799086155, 'alpha': 0.16006691101811607, 'eta': 0.6, 'gamma': 19, 'learning_rate': 0.01, 'colsample_bytree': 0.6, 'colsample_bynode': 0.4, 'min_child_weight': 228, 'max_depth': 7, 'subsample': 0.7}. Best is trial 3 with value: 0.04497681219284133.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:20:24] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:20:24,266] Trial 4 finished with value: -0.00012817774353645825 and parameters: {'n_estimators': 134, 'lambda': 0.30617015561997646, 'alpha': 0.7172902166559604, 'eta': 0.4, 'gamma': 22, 'learning_rate': 0.012, 'colsample_bytree': 1.0, 'colsample_bynode': 0.4, 'min_child_weight': 272, 'max_depth': 4, 'subsample': 0.5}. Best is trial 3 with value: 0.04497681219284133.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:24] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:24] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-09 22:20:24,846] Trial 5 finished with value: 0.0185266406917219 and parameters: {'n_estimators': 164, 'lambda': 0.15825498047320835, 'alpha': 0.6025888257200862, 'eta': 0.5, 'gamma': 20, 'learning_rate': 0.016, 'colsample_bytree': 0.5, 'colsample_bynode': 0.6, 'min_child_weight': 425, 'max_depth': 4, 'subsample': 0.8}. Best is trial 3 with value: 0.04497681219284133.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:25] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:25] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:20:25] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:20:25,730] Trial 6 finished with value: 0.06921707370622818 and parameters: {'n_estimators': 184, 'lambda': 0.9128133985090351, 'alpha': 0.5347378399128, 'eta': 0.8, 'gamma': 19, 'learning_rate': 0.01, 'colsample_bytree': 0.7, 'colsample_bynode': 0.4, 'min_child_weight': 30, 'max_depth': 6, 'subsample': 0.5}. Best is trial 6 with value: 0.06921707370622818.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:20:26] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:20:26,375] Trial 7 finished with value: 0.04717479585451256 and parameters: {'n_estimators': 50, 'lambda': 0.13026621463525545, 'alpha': 0.31295144927543406, 'eta': 0.7, 'gamma': 18, 'learning_rate': 0.016, 'colsample_bytree': 0.4, 'colsample_bynode': 0.6, 'min_child_weight': 516, 'max_depth': 5, 'subsample': 0.8}. Best is trial 6 with value: 0.06921707370622818.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:26] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:26] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-09 22:20:26,942] Trial 8 finished with value: 0.02026214940692897 and parameters: {'n_estimators': 142, 'lambda': 0.2110970639139124, 'alpha': 0.5881981238785446, 'eta': 1.0, 'gamma': 24, 'learning_rate': 0.014, 'colsample_bytree': 0.7, 'colsample_bynode': 0.3, 'min_child_weight': 377, 'max_depth': 3, 'subsample': 1.0}. Best is trial 6 with value: 0.06921707370622818.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:27] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:27] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:20:29] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:20:29,183] Trial 9 finished with value: 0.046294603893565336 and parameters: {'n_estimators': 170, 'lambda': 0.42197732987982794, 'alpha': 0.3227301593668079, 'eta': 0.5, 'gamma': 18, 'learning_rate': 0.008, 'colsample_bytree': 0.7, 'colsample_bynode': 0.6, 'min_child_weight': 141, 'max_depth': 5, 'subsample': 0.8}. Best is trial 6 with value: 0.06921707370622818.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:29] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:29] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-09 22:20:29,875] Trial 10 finished with value: 0.05038759156284126 and parameters: {'n_estimators': 220, 'lambda': 0.6921705480945166, 'alpha': 0.9652574974471948, 'eta': 0.8, 'gamma': 19, 'learning_rate': 0.01, 'colsample_bytree': 0.3, 'colsample_bynode': 0.7, 'min_child_weight': 50, 'max_depth': 6, 'subsample': 0.5}. Best is trial 6 with value: 0.06921707370622818.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:30] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:30] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:20:30] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:20:30,602] Trial 11 finished with value: 0.04461453112216306 and parameters: {'n_estimators': 220, 'lambda': 0.6810780741843255, 'alpha': 0.9881438784087386, 'eta': 0.8, 'gamma': 19, 'learning_rate': 0.01, 'colsample_bytree': 0.3, 'colsample_bynode': 0.7, 'min_child_weight': 16, 'max_depth': 6, 'subsample': 0.5}. Best is trial 6 with value: 0.06921707370622818.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:20:31] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:20:31,291] Trial 12 finished with value: 0.05398516968714165 and parameters: {'n_estimators': 204, 'lambda': 0.6730269925348911, 'alpha': 0.9982674980704732, 'eta': 0.8, 'gamma': 19, 'learning_rate': 0.018, 'colsample_bytree': 0.3, 'colsample_bynode': 0.8, 'min_child_weight': 29, 'max_depth': 6, 'subsample': 0.6}. Best is trial 6 with value: 0.06921707370622818.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:31] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:31] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-09 22:20:31,976] Trial 13 finished with value: 0.04798925593232925 and parameters: {'n_estimators': 186, 'lambda': 0.9923943246031256, 'alpha': 0.7973433783535946, 'eta': 0.8, 'gamma': 23, 'learning_rate': 0.018, 'colsample_bytree': 0.9, 'colsample_bynode': 0.8, 'min_child_weight': 112, 'max_depth': 6, 'subsample': 0.6}. Best is trial 6 with value: 0.06921707370622818.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:32] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:32] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:20:32] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:20:32,640] Trial 14 finished with value: 0.03613442156716749 and parameters: {'n_estimators': 244, 'lambda': 0.6557301108694786, 'alpha': 0.382331387955887, 'eta': 0.3, 'gamma': 25, 'learning_rate': 0.018, 'colsample_bytree': 0.3, 'colsample_bynode': 0.5, 'min_child_weight': 112, 'max_depth': 6, 'subsample': 0.6}. Best is trial 6 with value: 0.06921707370622818.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:20:33] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:20:33,331] Trial 15 finished with value: 0.04422985209177297 and parameters: {'n_estimators': 124, 'lambda': 0.6045519827938131, 'alpha': 0.8600186587560814, 'eta': 0.8, 'gamma': 19, 'learning_rate': 0.018, 'colsample_bytree': 0.7, 'colsample_bynode': 0.9, 'min_child_weight': 26, 'max_depth': 6, 'subsample': 0.6}. Best is trial 6 with value: 0.06921707370622818.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:33] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:33] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-09 22:20:33,906] Trial 16 finished with value: 0.041766226210012435 and parameters: {'n_estimators': 197, 'lambda': 0.7766512960852778, 'alpha': 0.6865826904767994, 'eta': 0.6, 'gamma': 19, 'learning_rate': 0.012, 'colsample_bytree': 0.9, 'colsample_bynode': 0.8, 'min_child_weight': 153, 'max_depth': 3, 'subsample': 0.6}. Best is trial 6 with value: 0.06921707370622818.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:34] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:34] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:20:34] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:20:34,609] Trial 17 finished with value: 0.05032139287171125 and parameters: {'n_estimators': 161, 'lambda': 0.9935336464261539, 'alpha': 0.41721521361906155, 'eta': 0.4, 'gamma': 21, 'learning_rate': 0.008, 'colsample_bytree': 0.4, 'colsample_bynode': 0.8, 'min_child_weight': 327, 'max_depth': 6, 'subsample': 0.5}. Best is trial 6 with value: 0.06921707370622818.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:20:35] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:20:35,363] Trial 18 finished with value: 0.02895025121970441 and parameters: {'n_estimators': 100, 'lambda': 0.5525579074663957, 'alpha': 0.1950152741481339, 'eta': 0.3, 'gamma': 24, 'learning_rate': 0.02, 'colsample_bytree': 1.0, 'colsample_bynode': 0.4, 'min_child_weight': 587, 'max_depth': 6, 'subsample': 0.6}. Best is trial 6 with value: 0.06921707370622818.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:35] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:35] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:20:36] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:20:36,038] Trial 19 finished with value: 0.061211825946274695 and parameters: {'n_estimators': 190, 'lambda': 0.7664679452212487, 'alpha': 0.471633184465036, 'eta': 1.0, 'gamma': 20, 'learning_rate': 0.01, 'colsample_bytree': 0.8, 'colsample_bynode': 0.9, 'min_child_weight': 88, 'max_depth': 6, 'subsample': 0.5}. Best is trial 6 with value: 0.06921707370622818.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:36] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:36] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-09 22:20:36,727] Trial 20 finished with value: 0.04527397653343661 and parameters: {'n_estimators': 18, 'lambda': 0.019101706707284727, 'alpha': 0.4949668354444747, 'eta': 1.0, 'gamma': 20, 'learning_rate': 0.01, 'colsample_bytree': 0.8, 'colsample_bynode': 0.9, 'min_child_weight': 182, 'max_depth': 7, 'subsample': 0.5}. Best is trial 6 with value: 0.06921707370622818.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:20:37] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:20:37,401] Trial 21 finished with value: 0.0576619305353827 and parameters: {'n_estimators': 195, 'lambda': 0.7473163075830912, 'alpha': 0.4600598313698751, 'eta': 1.0, 'gamma': 20, 'learning_rate': 0.01, 'colsample_bytree': 0.8, 'colsample_bynode': 0.9, 'min_child_weight': 78, 'max_depth': 6, 'subsample': 0.5}. Best is trial 6 with value: 0.06921707370622818.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:37] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:37] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:20:38] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:20:38,061] Trial 22 finished with value: 0.05431848615869689 and parameters: {'n_estimators': 182, 'lambda': 0.7766823282873879, 'alpha': 0.45458311672567603, 'eta': 1.0, 'gamma': 20, 'learning_rate': 0.01, 'colsample_bytree': 0.8, 'colsample_bynode': 0.9, 'min_child_weight': 84, 'max_depth': 6, 'subsample': 0.5}. Best is trial 6 with value: 0.06921707370622818.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:38] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:38] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-09 22:20:38,736] Trial 23 finished with value: 0.06274188958115318 and parameters: {'n_estimators': 152, 'lambda': 0.7619320700947418, 'alpha': 0.665192161971285, 'eta': 1.0, 'gamma': 20, 'learning_rate': 0.01, 'colsample_bytree': 0.8, 'colsample_bynode': 0.9, 'min_child_weight': 79, 'max_depth': 6, 'subsample': 0.5}. Best is trial 6 with value: 0.06921707370622818.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:39] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:39] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:20:39] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:20:39,479] Trial 24 finished with value: 0.06296469182528268 and parameters: {'n_estimators': 147, 'lambda': 0.9252907450968929, 'alpha': 0.6708492824928192, 'eta': 1.0, 'gamma': 20, 'learning_rate': 0.01, 'colsample_bytree': 0.8, 'colsample_bynode': 0.9, 'min_child_weight': 80, 'max_depth': 6, 'subsample': 0.5}. Best is trial 6 with value: 0.06921707370622818.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:20:40] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:20:40,083] Trial 25 finished with value: 0.03583427646090607 and parameters: {'n_estimators': 116, 'lambda': 0.9242929011709935, 'alpha': 0.6721973752504624, 'eta': 0.9, 'gamma': 23, 'learning_rate': 0.01, 'colsample_bytree': 0.7, 'colsample_bynode': 0.3, 'min_child_weight': 161, 'max_depth': 3, 'subsample': 0.5}. Best is trial 6 with value: 0.06921707370622818.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:40] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:40] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-09 22:20:40,693] Trial 26 finished with value: 0.042840373394608056 and parameters: {'n_estimators': 149, 'lambda': 0.9227677658372835, 'alpha': 0.6268226121925679, 'eta': 1.0, 'gamma': 20, 'learning_rate': 0.01, 'colsample_bytree': 0.8, 'colsample_bynode': 0.5, 'min_child_weight': 63, 'max_depth': 4, 'subsample': 0.5}. Best is trial 6 with value: 0.06921707370622818.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:41] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:41] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:20:41] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:20:41,432] Trial 27 finished with value: 0.04402214699745592 and parameters: {'n_estimators': 115, 'lambda': 0.8328400318452758, 'alpha': 0.764893947074091, 'eta': 1.0, 'gamma': 25, 'learning_rate': 0.01, 'colsample_bytree': 0.8, 'colsample_bynode': 0.4, 'min_child_weight': 125, 'max_depth': 6, 'subsample': 0.5}. Best is trial 6 with value: 0.06921707370622818.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:20:42] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:20:42,119] Trial 28 finished with value: 0.0439476590425493 and parameters: {'n_estimators': 153, 'lambda': 0.935190867128562, 'alpha': 0.8608094262023922, 'eta': 1.0, 'gamma': 20, 'learning_rate': 0.01, 'colsample_bytree': 0.7, 'colsample_bynode': 0.9, 'min_child_weight': 11, 'max_depth': 6, 'subsample': 0.7}. Best is trial 6 with value: 0.06921707370622818.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:42] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:42] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-09 22:20:42,830] Trial 29 finished with value: 0.02064098262192212 and parameters: {'n_estimators': 232, 'lambda': 0.848523010457099, 'alpha': 0.5287258934579528, 'eta': 0.5, 'gamma': 21, 'learning_rate': 0.014, 'colsample_bytree': 0.6, 'colsample_bynode': 0.9, 'min_child_weight': 205, 'max_depth': 7, 'subsample': 1.0}. Best is trial 6 with value: 0.06921707370622818.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:43] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:43] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:20:43] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:20:43,485] Trial 30 finished with value: 0.06956173346966613 and parameters: {'n_estimators': 172, 'lambda': 0.5833481728159042, 'alpha': 0.8599063035373478, 'eta': 0.7, 'gamma': 20, 'learning_rate': 0.008, 'colsample_bytree': 0.8, 'colsample_bynode': 0.4, 'min_child_weight': 220, 'max_depth': 6, 'subsample': 0.7}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:20:44] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:20:44,151] Trial 31 finished with value: 0.06572667647937563 and parameters: {'n_estimators': 175, 'lambda': 0.5785272182542649, 'alpha': 0.7450157982738307, 'eta': 0.7, 'gamma': 20, 'learning_rate': 0.008, 'colsample_bytree': 0.8, 'colsample_bynode': 0.4, 'min_child_weight': 203, 'max_depth': 6, 'subsample': 0.7}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:44] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:44] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-09 22:20:44,831] Trial 32 finished with value: 0.04083035957867147 and parameters: {'n_estimators': 173, 'lambda': 0.4801308478191104, 'alpha': 0.8868796310714342, 'eta': 0.7, 'gamma': 20, 'learning_rate': 0.008, 'colsample_bytree': 0.8, 'colsample_bynode': 0.4, 'min_child_weight': 248, 'max_depth': 6, 'subsample': 0.7}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:45] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:45] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:20:45] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:20:45,516] Trial 33 finished with value: 0.04555484464092517 and parameters: {'n_estimators': 180, 'lambda': 0.5567218955881994, 'alpha': 0.7489248927523257, 'eta': 0.7, 'gamma': 20, 'learning_rate': 0.008, 'colsample_bytree': 0.8, 'colsample_bynode': 0.4, 'min_child_weight': 323, 'max_depth': 6, 'subsample': 0.7}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:20:46] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:20:46,260] Trial 34 finished with value: 0.05313023187081568 and parameters: {'n_estimators': 205, 'lambda': 0.4097707897405721, 'alpha': 0.9320230989279008, 'eta': 0.7, 'gamma': 20, 'learning_rate': 0.008, 'colsample_bytree': 0.5, 'colsample_bynode': 0.4, 'min_child_weight': 207, 'max_depth': 7, 'subsample': 0.7}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:46] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:46] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-09 22:20:46,879] Trial 35 finished with value: 0.005578680525279118 and parameters: {'n_estimators': 125, 'lambda': 0.3321484438617551, 'alpha': 0.8140799248125158, 'eta': 0.7, 'gamma': 22, 'learning_rate': 0.008, 'colsample_bytree': 0.6, 'colsample_bynode': 1.0, 'min_child_weight': 274, 'max_depth': 5, 'subsample': 0.7}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:47] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:47] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:20:47] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:20:47,482] Trial 36 finished with value: 0.023245847213791103 and parameters: {'n_estimators': 137, 'lambda': 0.5884129099648524, 'alpha': 0.721325708918205, 'eta': 0.7, 'gamma': 25, 'learning_rate': 0.02, 'colsample_bytree': 1.0, 'colsample_bynode': 0.4, 'min_child_weight': 183, 'max_depth': 4, 'subsample': 0.7}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:20:48] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:20:48,335] Trial 37 finished with value: 0.04743275031457588 and parameters: {'n_estimators': 78, 'lambda': 0.4374525475538165, 'alpha': 0.5930679514000292, 'eta': 0.9, 'gamma': 18, 'learning_rate': 0.008, 'colsample_bytree': 0.8, 'colsample_bynode': 0.4, 'min_child_weight': 234, 'max_depth': 6, 'subsample': 0.7}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:48] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:48] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-09 22:20:48,993] Trial 38 finished with value: 0.030710792854167068 and parameters: {'n_estimators': 166, 'lambda': 0.34411343067631783, 'alpha': 0.8014384318900245, 'eta': 0.6, 'gamma': 24, 'learning_rate': 0.016, 'colsample_bytree': 0.4, 'colsample_bynode': 0.4, 'min_child_weight': 341, 'max_depth': 3, 'subsample': 1.0}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:49] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:49] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:20:49] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:20:49,632] Trial 39 finished with value: 0.028379219512343363 and parameters: {'n_estimators': 211, 'lambda': 0.8617666970218059, 'alpha': 0.5583744250941355, 'eta': 0.7, 'gamma': 22, 'learning_rate': 0.014, 'colsample_bytree': 0.5, 'colsample_bynode': 1.0, 'min_child_weight': 280, 'max_depth': 5, 'subsample': 0.7}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:20:50] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:20:50,249] Trial 40 finished with value: 0.05113547744018641 and parameters: {'n_estimators': 160, 'lambda': 0.5158098449458941, 'alpha': 0.6334348146350411, 'eta': 0.4, 'gamma': 23, 'learning_rate': 0.012, 'colsample_bytree': 0.7, 'colsample_bynode': 0.4, 'min_child_weight': 407, 'max_depth': 4, 'subsample': 0.8}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:50] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:50] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-09 22:20:50,994] Trial 41 finished with value: 0.05069813036015918 and parameters: {'n_estimators': 146, 'lambda': 0.817063905004963, 'alpha': 0.6551941960524466, 'eta': 0.7, 'gamma': 20, 'learning_rate': 0.008, 'colsample_bytree': 0.8, 'colsample_bynode': 0.3, 'min_child_weight': 106, 'max_depth': 6, 'subsample': 0.5}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:51] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:51] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:20:51] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:20:51,740] Trial 42 finished with value: 0.03838511243579827 and parameters: {'n_estimators': 177, 'lambda': 0.7251828502074681, 'alpha': 0.7097625026829464, 'eta': 0.3, 'gamma': 20, 'learning_rate': 0.01, 'colsample_bytree': 0.8, 'colsample_bynode': 0.7, 'min_child_weight': 45, 'max_depth': 6, 'subsample': 0.5}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:20:52] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:20:52,387] Trial 43 finished with value: 0.0440395817451869 and parameters: {'n_estimators': 131, 'lambda': 0.8869112877658483, 'alpha': 0.5534236328110009, 'eta': 0.8, 'gamma': 20, 'learning_rate': 0.016, 'colsample_bytree': 0.8, 'colsample_bynode': 0.9, 'min_child_weight': 180, 'max_depth': 6, 'subsample': 0.7}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:52] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:52] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:20:53] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:20:53,068] Trial 44 finished with value: 0.04606654227889907 and parameters: {'n_estimators': 153, 'lambda': 0.634886882950217, 'alpha': 0.9062149694110582, 'eta': 0.5, 'gamma': 19, 'learning_rate': 0.008, 'colsample_bytree': 0.9, 'colsample_bynode': 0.6, 'min_child_weight': 143, 'max_depth': 6, 'subsample': 0.5}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:53] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:53] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-09 22:20:53,746] Trial 45 finished with value: 0.054481513472651615 and parameters: {'n_estimators': 169, 'lambda': 0.712742166458085, 'alpha': 0.7638465522178881, 'eta': 1.0, 'gamma': 20, 'learning_rate': 0.01, 'colsample_bytree': 0.8, 'colsample_bynode': 0.4, 'min_child_weight': 41, 'max_depth': 6, 'subsample': 0.8}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:54] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:54] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:20:54] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:20:54,423] Trial 46 finished with value: 0.04001236976995667 and parameters: {'n_estimators': 106, 'lambda': 0.8018413040860302, 'alpha': 0.6103213160531912, 'eta': 0.7, 'gamma': 18, 'learning_rate': 0.02, 'colsample_bytree': 0.8, 'colsample_bynode': 0.5, 'min_child_weight': 74, 'max_depth': 6, 'subsample': 1.0}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:20:55] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:20:55,085] Trial 47 finished with value: 0.04115815096451927 and parameters: {'n_estimators': 139, 'lambda': 0.6182878243088049, 'alpha': 0.8448035645692503, 'eta': 0.8, 'gamma': 21, 'learning_rate': 0.012, 'colsample_bytree': 0.7, 'colsample_bynode': 0.4, 'min_child_weight': 294, 'max_depth': 6, 'subsample': 0.7}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:55] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:55] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-09 22:20:55,711] Trial 48 finished with value: 0.031141144888943928 and parameters: {'n_estimators': 223, 'lambda': 0.9433696417897826, 'alpha': 0.06946500213062201, 'eta': 0.6, 'gamma': 19, 'learning_rate': 0.01, 'colsample_bytree': 0.6, 'colsample_bynode': 0.7, 'min_child_weight': 222, 'max_depth': 5, 'subsample': 0.5}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:56] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:56] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:20:56] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:20:56,535] Trial 49 finished with value: 0.05317893209007139 and parameters: {'n_estimators': 156, 'lambda': 0.9737933417153959, 'alpha': 0.6939824656726257, 'eta': 0.4, 'gamma': 20, 'learning_rate': 0.008, 'colsample_bytree': 1.0, 'colsample_bynode': 0.6, 'min_child_weight': 127, 'max_depth': 7, 'subsample': 0.5}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:20:57] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:20:57,209] Trial 50 finished with value: 0.052272306981578025 and parameters: {'n_estimators': 199, 'lambda': 0.5235108285353173, 'alpha': 0.37175825700941967, 'eta': 0.9, 'gamma': 24, 'learning_rate': 0.014, 'colsample_bytree': 0.4, 'colsample_bynode': 0.9, 'min_child_weight': 486, 'max_depth': 6, 'subsample': 0.8}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:57] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:57] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-09 22:20:57,925] Trial 51 finished with value: 0.03995842807582208 and parameters: {'n_estimators': 189, 'lambda': 0.7720397667314017, 'alpha': 0.4940507037709648, 'eta': 1.0, 'gamma': 20, 'learning_rate': 0.01, 'colsample_bytree': 0.8, 'colsample_bynode': 0.9, 'min_child_weight': 96, 'max_depth': 6, 'subsample': 0.5}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:58] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:58] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:20:58] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:20:58,634] Trial 52 finished with value: 0.054125682254384244 and parameters: {'n_estimators': 189, 'lambda': 0.9003332845590575, 'alpha': 0.2800195268597828, 'eta': 1.0, 'gamma': 20, 'learning_rate': 0.01, 'colsample_bytree': 0.8, 'colsample_bynode': 0.9, 'min_child_weight': 44, 'max_depth': 6, 'subsample': 0.5}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:20:59] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:20:59,358] Trial 53 finished with value: 0.04256268156199419 and parameters: {'n_estimators': 174, 'lambda': 0.6635135085856625, 'alpha': 0.5651780007023157, 'eta': 1.0, 'gamma': 20, 'learning_rate': 0.01, 'colsample_bytree': 0.8, 'colsample_bynode': 0.9, 'min_child_weight': 59, 'max_depth': 6, 'subsample': 0.5}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:59] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:20:59] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:21:00] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:21:00,065] Trial 54 finished with value: 0.02070265332795378 and parameters: {'n_estimators': 163, 'lambda': 0.7353216087108948, 'alpha': 0.4428725352302119, 'eta': 0.8, 'gamma': 19, 'learning_rate': 0.01, 'colsample_bytree': 0.3, 'colsample_bynode': 0.9, 'min_child_weight': 85, 'max_depth': 6, 'subsample': 0.5}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:00] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:00] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-09 22:21:00,702] Trial 55 finished with value: 0.02531486968495114 and parameters: {'n_estimators': 253, 'lambda': 0.580924554542684, 'alpha': 0.6599146117576198, 'eta': 1.0, 'gamma': 20, 'learning_rate': 0.018, 'colsample_bytree': 0.8, 'colsample_bynode': 0.4, 'min_child_weight': 10, 'max_depth': 3, 'subsample': 0.5}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:01] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:01] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:21:01] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:21:01,372] Trial 56 finished with value: 0.06604381105192571 and parameters: {'n_estimators': 212, 'lambda': 0.6947980444044372, 'alpha': 0.5282402422415915, 'eta': 1.0, 'gamma': 20, 'learning_rate': 0.01, 'colsample_bytree': 0.9, 'colsample_bynode': 1.0, 'min_child_weight': 166, 'max_depth': 6, 'subsample': 0.5}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:02] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:02] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:21:02] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:21:03,022] Trial 57 finished with value: 0.05971239628860012 and parameters: {'n_estimators': 214, 'lambda': 0.6834200091749204, 'alpha': 0.8261099457533806, 'eta': 0.3, 'gamma': 22, 'learning_rate': 0.016, 'colsample_bytree': 0.9, 'colsample_bynode': 1.0, 'min_child_weight': 151, 'max_depth': 6, 'subsample': 0.7}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:03] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:03] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:21:03] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:21:03,626] Trial 58 finished with value: 0.06275379925938757 and parameters: {'n_estimators': 144, 'lambda': 0.8813988365472882, 'alpha': 0.7589058878786669, 'eta': 0.8, 'gamma': 23, 'learning_rate': 0.01, 'colsample_bytree': 0.9, 'colsample_bynode': 1.0, 'min_child_weight': 162, 'max_depth': 6, 'subsample': 0.6}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:21:04] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:21:04,205] Trial 59 finished with value: 0.05186281080720251 and parameters: {'n_estimators': 83, 'lambda': 0.9742063728758513, 'alpha': 0.7440319244599682, 'eta': 0.8, 'gamma': 23, 'learning_rate': 0.008, 'colsample_bytree': 0.9, 'colsample_bynode': 1.0, 'min_child_weight': 202, 'max_depth': 4, 'subsample': 0.6}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:04] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:04] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-09 22:21:04,840] Trial 60 finished with value: 0.05022756428392504 and parameters: {'n_estimators': 228, 'lambda': 0.8868534966021355, 'alpha': 0.7709689069261253, 'eta': 0.8, 'gamma': 25, 'learning_rate': 0.01, 'colsample_bytree': 0.9, 'colsample_bynode': 1.0, 'min_child_weight': 253, 'max_depth': 6, 'subsample': 0.6}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:05] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:05] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:21:05] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:21:05,537] Trial 61 finished with value: 0.06155617721157277 and parameters: {'n_estimators': 144, 'lambda': 0.8101958985493379, 'alpha': 0.5268840118517615, 'eta': 0.8, 'gamma': 23, 'learning_rate': 0.01, 'colsample_bytree': 0.9, 'colsample_bynode': 1.0, 'min_child_weight': 165, 'max_depth': 6, 'subsample': 0.6}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:21:06] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:21:06,176] Trial 62 finished with value: 0.06618584743058328 and parameters: {'n_estimators': 131, 'lambda': 0.6296011472422627, 'alpha': 0.7228480758740783, 'eta': 1.0, 'gamma': 23, 'learning_rate': 0.01, 'colsample_bytree': 0.9, 'colsample_bynode': 1.0, 'min_child_weight': 130, 'max_depth': 6, 'subsample': 0.6}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:06] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:06] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-09 22:21:06,794] Trial 63 finished with value: 0.06266619791357317 and parameters: {'n_estimators': 129, 'lambda': 0.5542843608419, 'alpha': 0.9408455184636123, 'eta': 0.8, 'gamma': 23, 'learning_rate': 0.01, 'colsample_bytree': 0.9, 'colsample_bynode': 1.0, 'min_child_weight': 124, 'max_depth': 6, 'subsample': 0.6}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:07] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:07] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:21:07] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:21:07,425] Trial 64 finished with value: 0.06416081461311073 and parameters: {'n_estimators': 68, 'lambda': 0.6442317441119054, 'alpha': 0.7181556121314772, 'eta': 0.5, 'gamma': 23, 'learning_rate': 0.01, 'colsample_bytree': 0.9, 'colsample_bynode': 1.0, 'min_child_weight': 178, 'max_depth': 6, 'subsample': 0.6}. Best is trial 30 with value: 0.06956173346966613.\n",
      "[I 2025-07-09 22:21:08,033] Trial 65 finished with value: 0.056041870371759214 and parameters: {'n_estimators': 46, 'lambda': 0.6393903306620299, 'alpha': 0.7271945686964779, 'eta': 0.5, 'gamma': 23, 'learning_rate': 0.018, 'colsample_bytree': 0.9, 'colsample_bynode': 1.0, 'min_child_weight': 185, 'max_depth': 6, 'subsample': 0.6}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:08] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:08] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:21:08] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:21:08,686] Trial 66 finished with value: 0.020052441406511457 and parameters: {'n_estimators': 56, 'lambda': 0.44274229456342284, 'alpha': 0.8822214195980287, 'eta': 0.5, 'gamma': 23, 'learning_rate': 0.02, 'colsample_bytree': 0.9, 'colsample_bynode': 0.8, 'min_child_weight': 235, 'max_depth': 6, 'subsample': 0.6}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:21:09] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:21:09,236] Trial 67 finished with value: 0.044054733521079914 and parameters: {'n_estimators': 34, 'lambda': 0.47316080821488893, 'alpha': 0.7854460117557324, 'eta': 0.5, 'gamma': 19, 'learning_rate': 0.01, 'colsample_bytree': 0.7, 'colsample_bynode': 1.0, 'min_child_weight': 133, 'max_depth': 3, 'subsample': 0.6}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:09] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:09] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-09 22:21:10,003] Trial 68 finished with value: 0.06547597564163377 and parameters: {'n_estimators': 65, 'lambda': 0.7013488559467231, 'alpha': 0.6246594846088287, 'eta': 0.7, 'gamma': 21, 'learning_rate': 0.01, 'colsample_bytree': 0.9, 'colsample_bynode': 0.3, 'min_child_weight': 219, 'max_depth': 7, 'subsample': 1.0}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:10] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:10] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:21:10] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:21:10,772] Trial 69 finished with value: 0.06606910641930427 and parameters: {'n_estimators': 71, 'lambda': 0.6040261746517673, 'alpha': 0.6186911563071943, 'eta': 0.7, 'gamma': 21, 'learning_rate': 0.008, 'colsample_bytree': 0.9, 'colsample_bynode': 0.3, 'min_child_weight': 207, 'max_depth': 7, 'subsample': 1.0}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:11] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:11] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:21:11] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:21:11,532] Trial 70 finished with value: 0.0646903970518461 and parameters: {'n_estimators': 97, 'lambda': 0.7013795957627612, 'alpha': 0.5925985517553275, 'eta': 0.7, 'gamma': 21, 'learning_rate': 0.008, 'colsample_bytree': 0.9, 'colsample_bynode': 0.3, 'min_child_weight': 208, 'max_depth': 7, 'subsample': 1.0}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:21:12] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:21:12,222] Trial 71 finished with value: 0.05099917072257263 and parameters: {'n_estimators': 69, 'lambda': 0.7010773272753938, 'alpha': 0.5956101130184291, 'eta': 0.7, 'gamma': 21, 'learning_rate': 0.008, 'colsample_bytree': 0.9, 'colsample_bynode': 0.3, 'min_child_weight': 256, 'max_depth': 7, 'subsample': 1.0}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:12] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:12] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-09 22:21:12,931] Trial 72 finished with value: 0.06166567792763141 and parameters: {'n_estimators': 97, 'lambda': 0.6057810241349553, 'alpha': 0.6361995863590787, 'eta': 0.7, 'gamma': 21, 'learning_rate': 0.008, 'colsample_bytree': 0.9, 'colsample_bynode': 0.3, 'min_child_weight': 214, 'max_depth': 7, 'subsample': 1.0}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:13] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:13] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:21:13] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:21:13,628] Trial 73 finished with value: 0.05162437270791782 and parameters: {'n_estimators': 67, 'lambda': 0.5867548245769467, 'alpha': 0.511875491525072, 'eta': 0.7, 'gamma': 21, 'learning_rate': 0.008, 'colsample_bytree': 0.9, 'colsample_bynode': 0.3, 'min_child_weight': 195, 'max_depth': 7, 'subsample': 1.0}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:21:14] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:21:14,336] Trial 74 finished with value: 0.05707415398754123 and parameters: {'n_estimators': 91, 'lambda': 0.5523110174725319, 'alpha': 0.5846432091997108, 'eta': 0.7, 'gamma': 21, 'learning_rate': 0.008, 'colsample_bytree': 0.9, 'colsample_bynode': 0.3, 'min_child_weight': 224, 'max_depth': 7, 'subsample': 1.0}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:14] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:14] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:21:15] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:21:15,051] Trial 75 finished with value: 0.046908189888672694 and parameters: {'n_estimators': 111, 'lambda': 0.6826331685841704, 'alpha': 0.48674368391818423, 'eta': 0.7, 'gamma': 21, 'learning_rate': 0.008, 'colsample_bytree': 0.5, 'colsample_bynode': 0.3, 'min_child_weight': 243, 'max_depth': 7, 'subsample': 1.0}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:15] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:15] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-09 22:21:15,741] Trial 76 finished with value: 0.04275545839854983 and parameters: {'n_estimators': 75, 'lambda': 0.4925938130165923, 'alpha': 0.6178316492197892, 'eta': 0.7, 'gamma': 21, 'learning_rate': 0.008, 'colsample_bytree': 0.9, 'colsample_bynode': 0.3, 'min_child_weight': 275, 'max_depth': 7, 'subsample': 1.0}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:21:16] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:21:16,426] Trial 77 finished with value: 0.022884267991133442 and parameters: {'n_estimators': 47, 'lambda': 0.617987920491063, 'alpha': 0.40990103931544386, 'eta': 0.7, 'gamma': 21, 'learning_rate': 0.012, 'colsample_bytree': 0.3, 'colsample_bynode': 0.3, 'min_child_weight': 193, 'max_depth': 7, 'subsample': 1.0}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:16] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:16] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:21:17] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:21:17,190] Trial 78 finished with value: 0.03799060000487024 and parameters: {'n_estimators': 57, 'lambda': 0.6625662932226895, 'alpha': 0.6880172691368209, 'eta': 0.7, 'gamma': 21, 'learning_rate': 0.008, 'colsample_bytree': 0.7, 'colsample_bynode': 0.3, 'min_child_weight': 298, 'max_depth': 7, 'subsample': 1.0}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:17] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:17] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-09 22:21:18,040] Trial 79 finished with value: 0.057224020361585554 and parameters: {'n_estimators': 236, 'lambda': 0.7074185171507344, 'alpha': 0.5448903496207603, 'eta': 0.7, 'gamma': 21, 'learning_rate': 0.014, 'colsample_bytree': 0.9, 'colsample_bynode': 0.5, 'min_child_weight': 164, 'max_depth': 7, 'subsample': 1.0}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:18] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:18] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:21:19] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:21:19,186] Trial 80 finished with value: 0.04510578321650395 and parameters: {'n_estimators': 86, 'lambda': 0.5262941794052709, 'alpha': 0.5726940387388328, 'eta': 0.7, 'gamma': 18, 'learning_rate': 0.008, 'colsample_bytree': 0.4, 'colsample_bynode': 0.4, 'min_child_weight': 212, 'max_depth': 7, 'subsample': 0.7}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:20] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:20] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:21:20] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:21:20,737] Trial 81 finished with value: 0.06332767061434916 and parameters: {'n_estimators': 39, 'lambda': 0.6436957151770595, 'alpha': 0.6483390496463943, 'eta': 0.6, 'gamma': 23, 'learning_rate': 0.01, 'colsample_bytree': 0.9, 'colsample_bynode': 0.3, 'min_child_weight': 173, 'max_depth': 5, 'subsample': 1.0}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:21] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:21] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:21:21] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:21:21,567] Trial 82 finished with value: 0.054199964216214876 and parameters: {'n_estimators': 61, 'lambda': 0.5770277093964635, 'alpha': 0.7057318906061997, 'eta': 0.5, 'gamma': 24, 'learning_rate': 0.01, 'colsample_bytree': 0.9, 'colsample_bynode': 1.0, 'min_child_weight': 148, 'max_depth': 7, 'subsample': 0.7}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:21:29] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:21:29,141] Trial 83 finished with value: 0.03270076229308462 and parameters: {'n_estimators': 73, 'lambda': 0.7450658758007466, 'alpha': 0.7349698757756775, 'eta': 0.4, 'gamma': 19, 'learning_rate': 0.008, 'colsample_bytree': 0.9, 'colsample_bynode': 0.4, 'min_child_weight': 232, 'max_depth': 4, 'subsample': 1.0}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:29] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:29] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:21:30] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:21:30,048] Trial 84 finished with value: 0.04407952483873031 and parameters: {'n_estimators': 96, 'lambda': 0.23889596874870578, 'alpha': 0.6765738422896856, 'eta': 0.9, 'gamma': 21, 'learning_rate': 0.01, 'colsample_bytree': 1.0, 'colsample_bynode': 0.8, 'min_child_weight': 109, 'max_depth': 7, 'subsample': 0.8}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:30] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:30] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-09 22:21:30,730] Trial 85 finished with value: 0.02593043425326634 and parameters: {'n_estimators': 120, 'lambda': 0.6176613716711945, 'alpha': 0.5857081424151136, 'eta': 0.7, 'gamma': 25, 'learning_rate': 0.02, 'colsample_bytree': 0.9, 'colsample_bynode': 0.7, 'min_child_weight': 260, 'max_depth': 6, 'subsample': 0.6}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:31] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:31] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:21:31] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:21:31,437] Trial 86 finished with value: 0.03666527809893763 and parameters: {'n_estimators': 182, 'lambda': 0.6487094697096524, 'alpha': 0.5304611297816039, 'eta': 0.7, 'gamma': 23, 'learning_rate': 0.016, 'colsample_bytree': 0.7, 'colsample_bynode': 0.6, 'min_child_weight': 319, 'max_depth': 6, 'subsample': 0.7}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:21:32] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:21:32,165] Trial 87 finished with value: 0.04826796134811062 and parameters: {'n_estimators': 202, 'lambda': 0.6889047599098269, 'alpha': 0.6143746868701959, 'eta': 0.3, 'gamma': 22, 'learning_rate': 0.01, 'colsample_bytree': 0.6, 'colsample_bynode': 0.4, 'min_child_weight': 177, 'max_depth': 7, 'subsample': 1.0}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:32] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:32] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-09 22:21:32,804] Trial 88 finished with value: 0.06495301214427544 and parameters: {'n_estimators': 105, 'lambda': 0.5658380476537126, 'alpha': 0.8030625606003545, 'eta': 0.7, 'gamma': 21, 'learning_rate': 0.008, 'colsample_bytree': 0.9, 'colsample_bynode': 0.3, 'min_child_weight': 197, 'max_depth': 5, 'subsample': 0.7}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:33] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:33] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:21:33] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:21:33,440] Trial 89 finished with value: 0.061707722589359026 and parameters: {'n_estimators': 103, 'lambda': 0.5325552182468767, 'alpha': 0.8422791295260378, 'eta': 0.7, 'gamma': 21, 'learning_rate': 0.008, 'colsample_bytree': 0.5, 'colsample_bynode': 0.3, 'min_child_weight': 195, 'max_depth': 5, 'subsample': 0.7}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:21:34] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:21:34,084] Trial 90 finished with value: 0.058629312034142636 and parameters: {'n_estimators': 109, 'lambda': 0.4009571324151357, 'alpha': 0.8167401095051944, 'eta': 0.7, 'gamma': 21, 'learning_rate': 0.008, 'colsample_bytree': 0.9, 'colsample_bynode': 0.3, 'min_child_weight': 216, 'max_depth': 5, 'subsample': 0.7}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:34] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:34] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:21:36] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:21:36,196] Trial 91 finished with value: 0.058039838419955136 and parameters: {'n_estimators': 64, 'lambda': 0.5753697256961918, 'alpha': 0.7763937014072301, 'eta': 0.7, 'gamma': 21, 'learning_rate': 0.008, 'colsample_bytree': 0.9, 'colsample_bynode': 0.3, 'min_child_weight': 189, 'max_depth': 5, 'subsample': 0.7}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:36] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:36] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-09 22:21:36,840] Trial 92 finished with value: 0.05292338123719461 and parameters: {'n_estimators': 77, 'lambda': 0.5990353003129365, 'alpha': 0.7971470680352621, 'eta': 1.0, 'gamma': 21, 'learning_rate': 0.008, 'colsample_bytree': 0.9, 'colsample_bynode': 1.0, 'min_child_weight': 137, 'max_depth': 5, 'subsample': 0.7}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:37] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:37] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:21:37] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:21:37,445] Trial 93 finished with value: 0.034191470598004224 and parameters: {'n_estimators': 86, 'lambda': 0.7220215292931867, 'alpha': 0.705839635076058, 'eta': 0.7, 'gamma': 18, 'learning_rate': 0.012, 'colsample_bytree': 0.9, 'colsample_bynode': 0.4, 'min_child_weight': 244, 'max_depth': 3, 'subsample': 0.6}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:21:38] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:21:38,148] Trial 94 finished with value: 0.05056867010048185 and parameters: {'n_estimators': 80, 'lambda': 0.7912562891321773, 'alpha': 0.6417884068336044, 'eta': 0.5, 'gamma': 19, 'learning_rate': 0.018, 'colsample_bytree': 0.9, 'colsample_bynode': 0.3, 'min_child_weight': 358, 'max_depth': 6, 'subsample': 0.7}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:38] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:38] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-09 22:21:38,795] Trial 95 finished with value: 0.04968266649097354 and parameters: {'n_estimators': 194, 'lambda': 0.6276425119133606, 'alpha': 0.8770699942463802, 'eta': 0.7, 'gamma': 20, 'learning_rate': 0.01, 'colsample_bytree': 0.9, 'colsample_bynode': 0.5, 'min_child_weight': 207, 'max_depth': 6, 'subsample': 1.0}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:39] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:39] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:21:39] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:21:39,406] Trial 96 finished with value: 0.03141043219466329 and parameters: {'n_estimators': 90, 'lambda': 0.543920178734223, 'alpha': 0.5143633903546172, 'eta': 1.0, 'gamma': 23, 'learning_rate': 0.008, 'colsample_bytree': 0.3, 'colsample_bynode': 1.0, 'min_child_weight': 156, 'max_depth': 6, 'subsample': 0.8}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:21:40] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:21:40,068] Trial 97 finished with value: 0.030134458356451812 and parameters: {'n_estimators': 212, 'lambda': 0.5110889386005855, 'alpha': 0.9053911932318487, 'eta': 0.4, 'gamma': 20, 'learning_rate': 0.01, 'colsample_bytree': 0.7, 'colsample_bynode': 0.4, 'min_child_weight': 170, 'max_depth': 6, 'subsample': 0.7}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:40] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [22:21:40] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-09 22:21:40,708] Trial 98 finished with value: 0.045408402475976814 and parameters: {'n_estimators': 118, 'lambda': 0.6706083213009735, 'alpha': 0.5489366886056223, 'eta': 0.6, 'gamma': 24, 'learning_rate': 0.014, 'colsample_bytree': 1.0, 'colsample_bynode': 0.3, 'min_child_weight': 120, 'max_depth': 5, 'subsample': 0.6}. Best is trial 30 with value: 0.06956173346966613.\n",
      "/mnt/d/Software/venv/py310_ubun/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [22:21:41] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  return func(**kwargs)\n",
      "[I 2025-07-09 22:21:41,294] Trial 99 finished with value: 0.008388988186242067 and parameters: {'n_estimators': 53, 'lambda': 0.7555537265449886, 'alpha': 0.8357983342479632, 'eta': 0.9, 'gamma': 21, 'learning_rate': 0.01, 'colsample_bytree': 0.4, 'colsample_bynode': 1.0, 'min_child_weight': 285, 'max_depth': 4, 'subsample': 1.0}. Best is trial 30 with value: 0.06956173346966613.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 100\n",
      "Best trial:\n",
      "  Value: 0.06956173346966613\n",
      "  Params: \n",
      "    n_estimators: 172\n",
      "    lambda: 0.5833481728159042\n",
      "    alpha: 0.8599063035373478\n",
      "    eta: 0.7\n",
      "    gamma: 20\n",
      "    learning_rate: 0.008\n",
      "    colsample_bytree: 0.8\n",
      "    colsample_bynode: 0.4\n",
      "    min_child_weight: 220\n",
      "    max_depth: 6\n",
      "    subsample: 0.7\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: 2025-07-08T21:35:04.500769+08:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.11.9\n",
      "IPython version      : 9.4.0\n",
      "\n",
      "Compiler    : Clang 13.0.0 (clang-1300.0.29.30)\n",
      "OS          : Darwin\n",
      "Release     : 24.5.0\n",
      "Machine     : arm64\n",
      "Processor   : arm\n",
      "CPU cores   : 10\n",
      "Architecture: 64bit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
