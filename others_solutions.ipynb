{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Solutions From Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Date | User | Change Type | Remarks |  \n",
    "| ---- | ---- | ----------- | ------- |\n",
    "| 10/07/2025   | Martin | Create  | Notebook to explore other's solutions on Kaggle | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Content\n",
    "\n",
    "* [Extending with Lots of Lag Features](#extending-with-lots-of-lag-features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extending with Lots of Lag Features\n",
    "\n",
    "_Notebook adapted from: https://www.kaggle.com/code/ruanpengju/drw-crypto-all-u-need-is-give-up_\n",
    "\n",
    "Exploring the addition of many lag variables and exponential decay to see interactions with the label. I want to learn more about what each function is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pl.read_parquet(\"data/train.parquet\")\n",
    "test = pl.read_parquet(\"data/test.parquet\")\n",
    "# submission = pl.read_csv(\"data/sample_submission.csv\")\n",
    "\n",
    "feat_impt = pl.read_csv(\"data/clean/perm_impt_45.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((525887, 897), (538150, 896))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape\n",
    "# train.shape\n",
    "# test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsure how these features were selected\n",
    "\n",
    "_NOTE: Might try using my own permutation importance based on what I found with 45 features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define global variables\n",
    "\n",
    "# # Baseline\n",
    "# FEATURES = [\n",
    "#   \"X863\", \"X856\", \"X344\", \"X598\", \"X862\", \"X385\", \"X852\", \"X603\", \"X860\", \"X674\",\n",
    "#   \"X415\", \"X345\", \"X137\", \"X855\", \"X174\", \"X302\", \"X178\", \"X532\", \"X168\", \"X612\",\n",
    "#   \"bid_qty\", \"ask_qty\", \"buy_qty\", \"sell_qty\", \"volume\", \"X888\", \"X421\", \"X333\",\n",
    "#   \"X21\", \"X20\", \"X28\", \"X29\", \"X19\", \"X27\", \"X22\", \"X39\",\n",
    "# ]\n",
    "\n",
    "# Feature Importance\n",
    "FEATURES = list(feat_impt.columns)[:-2] + [\"bid_qty\", \"ask_qty\", \"buy_qty\", \"sell_qty\", \"volume\"]\n",
    "\n",
    "RANDOM_STATE = 123\n",
    "LAGS = [1, 2, 3, 4, 20, \n",
    "  60, # 1 hour\n",
    "  180, # 3 hours\n",
    "  240, # 4 hours\n",
    "  60*24, # 1 day\n",
    "  60*24*7, # 1 week\n",
    "  60*24*14, # 2 weeks\n",
    "  60*24*21 # 3 weeks\n",
    "]\n",
    "\n",
    "len(FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_time_decay_weights(n: int, decay: float=0.9) -> np.ndarray:\n",
    "  \"\"\"Creates a set of exponentially decaying weights that is normalised\n",
    "\n",
    "  Args:\n",
    "      n (int): number of weights to create\n",
    "      decay (float, optional): exponential decay factor. Defaults to 0.9.\n",
    "\n",
    "  Returns:\n",
    "      np.ndarray: numpy array of weights\n",
    "  \"\"\"\n",
    "  positions = np.arange(n)\n",
    "  normalized = positions / (n - 1)\n",
    "  weights = decay ** (1.0 - normalized)\n",
    "\n",
    "  return weights * n / weights.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(df: pl.DataFrame) -> pl.DataFrame:\n",
    "  # Create interaction features\n",
    "  df = df.with_columns(\n",
    "    bid_ask_interaction = pl.col('bid_qty') * pl.col('ask_qty'),\n",
    "    bid_buy_interaction = pl.col('bid_qty') * pl.col('buy_qty'),\n",
    "    bid_sell_interaction = pl.col('bid_qty') * pl.col('sell_qty'),\n",
    "    ask_buy_interaction = pl.col('ask_qty') * pl.col('buy_qty'),\n",
    "    ask_sell_interaction = pl.col('ask_qty') * pl.col('sell_qty'),\n",
    "  )\n",
    "\n",
    "  # Additional financial metrics\n",
    "  df = df.with_columns(\n",
    "    volume_weighted_sell = pl.col('sell_qty') * pl.col('volume'),\n",
    "    buy_sell_ratio = pl.col('buy_qty') / (pl.col('sell_qty') + 1e-6),\n",
    "    selling_pressure = pl.col('sell_qty') / (pl.col('volume') + 1e-6),\n",
    "    log_volume = np.log1p(pl.col('volume')),\n",
    "    effective_spread_proxy = np.abs(pl.col('buy_qty') - pl.col('sell_qty')) / (pl.col('volume') + 1e-6),\n",
    "    bid_ask_imbalance = (pl.col('bid_qty') - pl.col('ask_qty')) / (pl.col('bid_qty') + pl.col('ask_qty') + 1e-6),\n",
    "    order_flow_imbalance = (pl.col('buy_qty') - pl.col('sell_qty')) / (pl.col('buy_qty') + pl.col('sell_qty') + 1e-6),\n",
    "    liquidity_ratio = (pl.col('bid_qty') + pl.col('ask_qty')) / (pl.col('volume') + 1e-6)\n",
    "  )\n",
    "\n",
    "  new_features = [\n",
    "    \"bid_ask_interaction\",\n",
    "    \"bid_buy_interaction\",\n",
    "    \"bid_sell_interaction\",\n",
    "    \"ask_buy_interaction\",\n",
    "    \"ask_sell_interaction\",\n",
    "    \"volume_weighted_sell\",\n",
    "    \"buy_sell_ratio\",\n",
    "    \"selling_pressure\",\n",
    "    \"log_volume\",\n",
    "    \"effective_spread_proxy\",\n",
    "    \"bid_ask_imbalance\",\n",
    "    \"order_flow_imbalance\",\n",
    "    \"liquidity_ratio\"\n",
    "  ]\n",
    "\n",
    "  # Generate volality features - Moving Average and Standard Deviation\n",
    "  print(\"Generating volatility and trend features\")\n",
    "  features_for_stats = ['bid_qty', 'ask_qty', 'buy_qty', 'sell_qty', 'volume', 'bid_ask_imbalance', 'order_flow_imbalance']\n",
    "  windows = [10, 60]\n",
    "\n",
    "  for col in features_for_stats:\n",
    "    if col in df.columns:\n",
    "      for w in windows:\n",
    "        df = df.with_columns(\n",
    "          pl.col(col).rolling_mean(window_size=w, min_samples=1).alias(f\"{col}_ma_{w}\"),\n",
    "          pl.col(col).rolling_std(window_size=w, min_samples=1).alias(f\"{col}_std_{w}\"),\n",
    "        )\n",
    "  \n",
    "  # Generate lead and lag features - For all original and newly created features\n",
    "  # print(\"Generate lead/ lag features\")\n",
    "  # features_for_lags = FEATURES + new_features\n",
    "  # for col in features_for_lags:\n",
    "  #   if col in df.columns:\n",
    "  #     for lag in LAGS:\n",
    "  #       df = df.with_columns(\n",
    "  #         pl.col(col).shift(lag).alias(f\"{col}_lag_{lag}\"),\n",
    "  #         pl.col(col).shift(-lag).alias(f\"{col}_lead_{lag}\"),\n",
    "  #       )\n",
    "  \n",
    "  # Handle infinite and missing values\n",
    "  df = df.with_columns(\n",
    "    pl.when(pl.col(pl.Float64).is_infinite())\n",
    "    .then(None)\n",
    "    .otherwise(pl.col(pl.Float64))\n",
    "    .name.keep()\n",
    "  )\n",
    "  df = df.with_columns(pl.all().fill_null(strategy='forward'))\n",
    "  df = df.with_columns(pl.all().fill_null(strategy='backward'))\n",
    "  df = df.with_columns(pl.all().fill_null(0))\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to shuffle the data according to random_state 700\n",
    "def sort_test_df_by_time(df):\n",
    "  assert len(df.shape) == 2\n",
    "  assert df.shape[0] == 538150\n",
    "\n",
    "  n = df.shape[0]\n",
    "  t = pd.Series(np.arange(n))\n",
    "  t = t.sample(n=n, random_state=700)\n",
    "\n",
    "  t = pd.Series(np.arange(n), index=t.to_numpy()).sort_index()\n",
    "  return df.iloc[t.to_numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating volatility and trend features\n",
      "Generating volatility and trend features\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(538150, 77)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply transformations\n",
    "df_train = train.select(FEATURES)\n",
    "df_train = add_features(df_train)\n",
    "df_train = df_train.with_columns(\n",
    "  label=train['label']\n",
    ")\n",
    "df_train.shape\n",
    "\n",
    "df_test = test.select(FEATURES)\n",
    "df_test = add_features(df_test)\n",
    "df_test.shape\n",
    "\n",
    "# # Uncomment: To save\n",
    "# df_train.write_parquet(\"data/clean/others.parquet\")\n",
    "# df_test.write_parquet(\"data/clean/test_others.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 78)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>X863</th><th>X856</th><th>X344</th><th>X598</th><th>X862</th><th>X385</th><th>X852</th><th>X603</th><th>X860</th><th>X674</th><th>X415</th><th>X345</th><th>X137</th><th>X855</th><th>X174</th><th>X302</th><th>X178</th><th>X532</th><th>X168</th><th>X612</th><th>bid_qty</th><th>ask_qty</th><th>buy_qty</th><th>sell_qty</th><th>volume</th><th>X888</th><th>X421</th><th>X333</th><th>X21</th><th>X20</th><th>X28</th><th>X29</th><th>X19</th><th>X27</th><th>X22</th><th>X39</th><th>bid_ask_interaction</th><th>&hellip;</th><th>volume_weighted_sell</th><th>buy_sell_ratio</th><th>selling_pressure</th><th>log_volume</th><th>effective_spread_proxy</th><th>bid_ask_imbalance</th><th>order_flow_imbalance</th><th>liquidity_ratio</th><th>bid_qty_ma_10</th><th>bid_qty_std_10</th><th>bid_qty_ma_60</th><th>bid_qty_std_60</th><th>ask_qty_ma_10</th><th>ask_qty_std_10</th><th>ask_qty_ma_60</th><th>ask_qty_std_60</th><th>buy_qty_ma_10</th><th>buy_qty_std_10</th><th>buy_qty_ma_60</th><th>buy_qty_std_60</th><th>sell_qty_ma_10</th><th>sell_qty_std_10</th><th>sell_qty_ma_60</th><th>sell_qty_std_60</th><th>volume_ma_10</th><th>volume_std_10</th><th>volume_ma_60</th><th>volume_std_60</th><th>bid_ask_imbalance_ma_10</th><th>bid_ask_imbalance_std_10</th><th>bid_ask_imbalance_ma_60</th><th>bid_ask_imbalance_std_60</th><th>order_flow_imbalance_ma_10</th><th>order_flow_imbalance_std_10</th><th>order_flow_imbalance_ma_60</th><th>order_flow_imbalance_std_60</th><th>label</th></tr><tr><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>&hellip;</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>0.21857</td><td>-0.216525</td><td>-0.362607</td><td>0.075641</td><td>-1.027483</td><td>-0.589209</td><td>0.878094</td><td>0.839766</td><td>0.541286</td><td>0.165674</td><td>-1.035101</td><td>0.260984</td><td>0.656033</td><td>0.418618</td><td>-0.167949</td><td>-0.454341</td><td>-0.033564</td><td>0.594644</td><td>-0.258087</td><td>0.817685</td><td>15.283</td><td>8.425</td><td>176.405</td><td>44.984</td><td>221.389</td><td>0.210153</td><td>-0.62566</td><td>0.362469</td><td>0.816321</td><td>0.58567</td><td>1.183991</td><td>1.474789</td><td>0.883229</td><td>0.953631</td><td>0.529973</td><td>0.966243</td><td>128.759275</td><td>&hellip;</td><td>9958.962776</td><td>3.921505</td><td>0.20319</td><td>5.404428</td><td>0.59362</td><td>0.289269</td><td>0.59362</td><td>0.107088</td><td>15.283</td><td>16.480538</td><td>15.283</td><td>16.480538</td><td>8.425</td><td>4.305573</td><td>8.425</td><td>4.305573</td><td>176.405</td><td>247.092101</td><td>176.405</td><td>247.092101</td><td>44.984</td><td>195.844537</td><td>44.984</td><td>195.844537</td><td>221.389</td><td>442.936637</td><td>221.389</td><td>442.936637</td><td>0.289269</td><td>0.421841</td><td>0.289269</td><td>0.421841</td><td>0.59362</td><td>0.249693</td><td>0.59362</td><td>0.249693</td><td>0.562539</td></tr><tr><td>0.088014</td><td>-0.180112</td><td>-0.376922</td><td>0.067653</td><td>-1.024055</td><td>-0.588391</td><td>0.891413</td><td>0.839766</td><td>0.450331</td><td>0.165214</td><td>-1.029366</td><td>0.260621</td><td>0.655122</td><td>0.424977</td><td>-0.167483</td><td>-0.450767</td><td>-0.033518</td><td>0.578271</td><td>-0.256658</td><td>0.817685</td><td>38.59</td><td>2.336</td><td>525.846</td><td>321.95</td><td>847.796</td><td>0.209573</td><td>-0.623925</td><td>0.36046</td><td>0.674792</td><td>0.442391</td><td>1.015943</td><td>1.312735</td><td>0.591695</td><td>0.776628</td><td>0.460741</td><td>0.953242</td><td>90.14624</td><td>&hellip;</td><td>272947.9222</td><td>1.633316</td><td>0.379749</td><td>6.743819</td><td>0.240501</td><td>0.885843</td><td>0.240501</td><td>0.048273</td><td>26.9365</td><td>16.480538</td><td>26.9365</td><td>16.480538</td><td>5.3805</td><td>4.305573</td><td>5.3805</td><td>4.305573</td><td>351.1255</td><td>247.092101</td><td>351.1255</td><td>247.092101</td><td>183.467</td><td>195.844537</td><td>183.467</td><td>195.844537</td><td>534.5925</td><td>442.936637</td><td>534.5925</td><td>442.936637</td><td>0.587556</td><td>0.421841</td><td>0.587556</td><td>0.421841</td><td>0.417061</td><td>0.249693</td><td>0.417061</td><td>0.249693</td><td>0.533686</td></tr><tr><td>-0.147363</td><td>-0.265966</td><td>-0.368205</td><td>0.067288</td><td>-1.024056</td><td>-0.587575</td><td>0.859856</td><td>0.833221</td><td>0.420681</td><td>0.164756</td><td>-1.023663</td><td>0.26026</td><td>0.654213</td><td>0.409942</td><td>-0.167019</td><td>-0.45531</td><td>-0.033471</td><td>0.577898</td><td>-0.255236</td><td>0.809375</td><td>0.442</td><td>60.25</td><td>159.227</td><td>136.369</td><td>295.596</td><td>0.208993</td><td>-0.622194</td><td>0.358463</td><td>0.610116</td><td>0.376524</td><td>0.917205</td><td>1.219124</td><td>0.457268</td><td>0.670816</td><td>0.429751</td><td>0.952246</td><td>26.6305</td><td>&hellip;</td><td>40310.130924</td><td>1.167619</td><td>0.461336</td><td>5.692371</td><td>0.077329</td><td>-0.985435</td><td>0.077329</td><td>0.205321</td><td>18.105</td><td>19.229931</td><td>18.105</td><td>19.229931</td><td>23.670333</td><td>31.82488</td><td>23.670333</td><td>31.82488</td><td>287.159333</td><td>206.887082</td><td>287.159333</td><td>206.887082</td><td>167.767667</td><td>141.127419</td><td>167.767667</td><td>141.127419</td><td>454.927</td><td>342.251674</td><td>454.927</td><td>342.251674</td><td>0.063226</td><td>0.955898</td><td>0.063226</td><td>0.955898</td><td>0.303817</td><td>0.263905</td><td>0.303817</td><td>0.263905</td><td>0.546505</td></tr><tr><td>-0.09459</td><td>-0.322244</td><td>-0.356326</td><td>0.069881</td><td>-1.024058</td><td>-0.647419</td><td>0.839141</td><td>0.826309</td><td>0.386584</td><td>0.164299</td><td>-1.21445</td><td>0.259899</td><td>0.653305</td><td>0.400075</td><td>-0.18045</td><td>-0.44363</td><td>-0.033425</td><td>0.577524</td><td>-0.281572</td><td>0.807937</td><td>4.865</td><td>21.016</td><td>335.742</td><td>124.963</td><td>460.705</td><td>0.208416</td><td>-0.718833</td><td>0.356477</td><td>0.618529</td><td>0.383696</td><td>1.044941</td><td>1.353001</td><td>0.468778</td><td>0.789646</td><td>0.435326</td><td>1.003724</td><td>102.24284</td><td>&hellip;</td><td>57571.078915</td><td>2.686731</td><td>0.271243</td><td>6.134926</td><td>0.457514</td><td>-0.624049</td><td>0.457514</td><td>0.056177</td><td>14.795</td><td>17.039696</td><td>14.795</td><td>17.039696</td><td>23.00675</td><td>26.018776</td><td>23.00675</td><td>26.018776</td><td>299.305</td><td>170.660224</td><td>299.305</td><td>170.660224</td><td>157.0665</td><td>117.200792</td><td>157.0665</td><td>117.200792</td><td>456.3715</td><td>279.462255</td><td>456.3715</td><td>279.462255</td><td>-0.108593</td><td>0.852788</td><td>-0.108593</td><td>0.852788</td><td>0.342241</td><td>0.228771</td><td>0.342241</td><td>0.228771</td><td>0.357703</td></tr><tr><td>0.162221</td><td>-0.369625</td><td>-0.347715</td><td>0.072288</td><td>-1.02406</td><td>-0.646521</td><td>0.82168</td><td>0.800184</td><td>0.389969</td><td>0.163843</td><td>-1.207722</td><td>0.259538</td><td>0.652398</td><td>0.391759</td><td>-0.179949</td><td>-0.438645</td><td>-0.033378</td><td>0.577151</td><td>-0.280012</td><td>0.795718</td><td>27.158</td><td>3.451</td><td>98.411</td><td>44.407</td><td>142.818</td><td>0.207839</td><td>-0.716839</td><td>0.354503</td><td>0.623192</td><td>0.3871</td><td>1.047708</td><td>1.36188</td><td>0.472732</td><td>0.78375</td><td>0.439034</td><td>0.993904</td><td>93.722258</td><td>&hellip;</td><td>6342.118926</td><td>2.216115</td><td>0.310934</td><td>4.968549</td><td>0.378132</td><td>0.774511</td><td>0.378132</td><td>0.214322</td><td>17.2676</td><td>15.758559</td><td>17.2676</td><td>15.758559</td><td>19.0956</td><td>24.170602</td><td>19.0956</td><td>24.170602</td><td>259.1262</td><td>172.960584</td><td>259.1262</td><td>172.960584</td><td>134.5346</td><td>113.315717</td><td>134.5346</td><td>113.315717</td><td>393.6608</td><td>279.709712</td><td>393.6608</td><td>279.709712</td><td>0.068028</td><td>0.837502</td><td>0.068028</td><td>0.837502</td><td>0.349419</td><td>0.198771</td><td>0.349419</td><td>0.198771</td><td>0.362452</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 78)\n",
       "┌───────────┬───────────┬───────────┬──────────┬───┬────────────┬───────────┬───────────┬──────────┐\n",
       "│ X863      ┆ X856      ┆ X344      ┆ X598     ┆ … ┆ order_flow ┆ order_flo ┆ order_flo ┆ label    │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ ---      ┆   ┆ _imbalance ┆ w_imbalan ┆ w_imbalan ┆ ---      │\n",
       "│ f64       ┆ f64       ┆ f64       ┆ f64      ┆   ┆ _std_10    ┆ ce_ma_60  ┆ ce_std_60 ┆ f64      │\n",
       "│           ┆           ┆           ┆          ┆   ┆ ---        ┆ ---       ┆ ---       ┆          │\n",
       "│           ┆           ┆           ┆          ┆   ┆ f64        ┆ f64       ┆ f64       ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪══════════╪═══╪════════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 0.21857   ┆ -0.216525 ┆ -0.362607 ┆ 0.075641 ┆ … ┆ 0.249693   ┆ 0.59362   ┆ 0.249693  ┆ 0.562539 │\n",
       "│ 0.088014  ┆ -0.180112 ┆ -0.376922 ┆ 0.067653 ┆ … ┆ 0.249693   ┆ 0.417061  ┆ 0.249693  ┆ 0.533686 │\n",
       "│ -0.147363 ┆ -0.265966 ┆ -0.368205 ┆ 0.067288 ┆ … ┆ 0.263905   ┆ 0.303817  ┆ 0.263905  ┆ 0.546505 │\n",
       "│ -0.09459  ┆ -0.322244 ┆ -0.356326 ┆ 0.069881 ┆ … ┆ 0.228771   ┆ 0.342241  ┆ 0.228771  ┆ 0.357703 │\n",
       "│ 0.162221  ┆ -0.369625 ┆ -0.347715 ┆ 0.072288 ┆ … ┆ 0.198771   ┆ 0.349419  ┆ 0.198771  ┆ 0.362452 │\n",
       "└───────────┴───────────┴───────────┴──────────┴───┴────────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 77)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>X863</th><th>X856</th><th>X344</th><th>X598</th><th>X862</th><th>X385</th><th>X852</th><th>X603</th><th>X860</th><th>X674</th><th>X415</th><th>X345</th><th>X137</th><th>X855</th><th>X174</th><th>X302</th><th>X178</th><th>X532</th><th>X168</th><th>X612</th><th>bid_qty</th><th>ask_qty</th><th>buy_qty</th><th>sell_qty</th><th>volume</th><th>X888</th><th>X421</th><th>X333</th><th>X21</th><th>X20</th><th>X28</th><th>X29</th><th>X19</th><th>X27</th><th>X22</th><th>X39</th><th>bid_ask_interaction</th><th>&hellip;</th><th>ask_sell_interaction</th><th>volume_weighted_sell</th><th>buy_sell_ratio</th><th>selling_pressure</th><th>log_volume</th><th>effective_spread_proxy</th><th>bid_ask_imbalance</th><th>order_flow_imbalance</th><th>liquidity_ratio</th><th>bid_qty_ma_10</th><th>bid_qty_std_10</th><th>bid_qty_ma_60</th><th>bid_qty_std_60</th><th>ask_qty_ma_10</th><th>ask_qty_std_10</th><th>ask_qty_ma_60</th><th>ask_qty_std_60</th><th>buy_qty_ma_10</th><th>buy_qty_std_10</th><th>buy_qty_ma_60</th><th>buy_qty_std_60</th><th>sell_qty_ma_10</th><th>sell_qty_std_10</th><th>sell_qty_ma_60</th><th>sell_qty_std_60</th><th>volume_ma_10</th><th>volume_std_10</th><th>volume_ma_60</th><th>volume_std_60</th><th>bid_ask_imbalance_ma_10</th><th>bid_ask_imbalance_std_10</th><th>bid_ask_imbalance_ma_60</th><th>bid_ask_imbalance_std_60</th><th>order_flow_imbalance_ma_10</th><th>order_flow_imbalance_std_10</th><th>order_flow_imbalance_ma_60</th><th>order_flow_imbalance_std_60</th></tr><tr><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>&hellip;</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>-0.270279</td><td>0.888982</td><td>0.183128</td><td>1.002431</td><td>0.242743</td><td>-0.28028</td><td>1.145126</td><td>1.244533</td><td>0.168711</td><td>1.030041</td><td>-0.707083</td><td>-0.008769</td><td>-0.078846</td><td>0.602466</td><td>0.020813</td><td>-0.606213</td><td>0.26272</td><td>0.010969</td><td>0.034217</td><td>0.874687</td><td>0.114</td><td>12.121</td><td>10.587</td><td>10.971</td><td>21.558</td><td>1.567979</td><td>-0.744742</td><td>-4.2232e-8</td><td>-0.041204</td><td>-0.079453</td><td>-0.243297</td><td>-0.186772</td><td>-0.227923</td><td>-0.276421</td><td>0.048349</td><td>0.475384</td><td>1.381794</td><td>&hellip;</td><td>132.979491</td><td>236.512818</td><td>0.964999</td><td>0.508906</td><td>3.11609</td><td>0.017812</td><td>-0.981365</td><td>-0.017812</td><td>0.567539</td><td>0.114</td><td>1.634831</td><td>0.114</td><td>1.634831</td><td>12.121</td><td>6.476391</td><td>12.121</td><td>6.476391</td><td>10.587</td><td>88.850795</td><td>10.587</td><td>88.850795</td><td>10.971</td><td>0.942573</td><td>10.971</td><td>0.942573</td><td>21.558</td><td>89.793369</td><td>21.558</td><td>89.793369</td><td>-0.981365</td><td>0.623587</td><td>-0.981365</td><td>0.623587</td><td>-0.017812</td><td>0.602563</td><td>-0.017812</td><td>0.602563</td></tr><tr><td>-0.356306</td><td>0.174188</td><td>1.252857</td><td>0.395232</td><td>0.955962</td><td>0.164827</td><td>0.831423</td><td>-0.247774</td><td>-0.502716</td><td>0.80456</td><td>-0.427253</td><td>-0.101519</td><td>-0.359345</td><td>1.187569</td><td>0.388479</td><td>0.340249</td><td>0.870314</td><td>-0.26096</td><td>0.223421</td><td>-0.43828</td><td>2.426</td><td>2.962</td><td>136.241</td><td>12.304</td><td>148.545</td><td>0.050925</td><td>-0.2114</td><td>0.002842</td><td>-0.227728</td><td>-0.047501</td><td>0.128473</td><td>0.023283</td><td>0.139376</td><td>0.179227</td><td>-0.145745</td><td>0.140607</td><td>7.185812</td><td>&hellip;</td><td>36.444448</td><td>1827.69768</td><td>11.072902</td><td>0.08283</td><td>5.007597</td><td>0.83434</td><td>-0.09948</td><td>0.83434</td><td>0.036272</td><td>1.27</td><td>1.634831</td><td>1.27</td><td>1.634831</td><td>7.5415</td><td>6.476391</td><td>7.5415</td><td>6.476391</td><td>73.414</td><td>88.850795</td><td>73.414</td><td>88.850795</td><td>11.6375</td><td>0.942573</td><td>11.6375</td><td>0.942573</td><td>85.0515</td><td>89.793369</td><td>85.0515</td><td>89.793369</td><td>-0.540423</td><td>0.623587</td><td>-0.540423</td><td>0.623587</td><td>0.408264</td><td>0.602563</td><td>0.408264</td><td>0.602563</td></tr><tr><td>0.268433</td><td>-0.26551</td><td>0.084397</td><td>0.092053</td><td>-0.488119</td><td>-0.27619</td><td>0.983454</td><td>0.625488</td><td>0.273964</td><td>0.795365</td><td>-0.193592</td><td>0.593242</td><td>0.055477</td><td>0.589635</td><td>0.043473</td><td>-0.43891</td><td>-0.099887</td><td>-0.121893</td><td>0.10822</td><td>0.085317</td><td>1.085</td><td>2.343</td><td>23.39</td><td>57.171</td><td>80.561</td><td>0.072535</td><td>-0.170362</td><td>0.208982</td><td>0.060063</td><td>0.10225</td><td>0.044225</td><td>0.003683</td><td>0.197985</td><td>0.046509</td><td>-0.139541</td><td>0.179177</td><td>2.542155</td><td>&hellip;</td><td>133.951653</td><td>4605.752931</td><td>0.409123</td><td>0.709661</td><td>4.401351</td><td>0.419322</td><td>-0.366978</td><td>-0.419322</td><td>0.042552</td><td>1.208333</td><td>1.160924</td><td>1.208333</td><td>1.160924</td><td>5.808667</td><td>5.475395</td><td>5.808667</td><td>5.475395</td><td>56.739333</td><td>69.147418</td><td>56.739333</td><td>69.147418</td><td>26.815333</td><td>26.297226</td><td>26.815333</td><td>26.297226</td><td>83.554667</td><td>63.546409</td><td>83.554667</td><td>63.546409</td><td>-0.482608</td><td>0.45217</td><td>-0.482608</td><td>0.45217</td><td>0.132402</td><td>0.640188</td><td>0.132402</td><td>0.640188</td></tr><tr><td>-0.364048</td><td>1.247777</td><td>0.488409</td><td>0.320689</td><td>0.145365</td><td>-0.155654</td><td>1.79358</td><td>0.781413</td><td>-0.312154</td><td>0.82964</td><td>0.318894</td><td>0.001211</td><td>-0.021331</td><td>0.945045</td><td>2.992349</td><td>-0.622701</td><td>0.550969</td><td>-0.175071</td><td>3.234477</td><td>0.081534</td><td>14.793</td><td>1.117</td><td>116.518</td><td>13.082</td><td>129.6</td><td>1.381752</td><td>0.257872</td><td>7.2901e-9</td><td>-0.021846</td><td>-0.043811</td><td>0.156303</td><td>0.179812</td><td>-0.101949</td><td>0.151133</td><td>0.030501</td><td>0.133269</td><td>16.523781</td><td>&hellip;</td><td>14.612594</td><td>1695.4272</td><td>8.906741</td><td>0.100941</td><td>4.872139</td><td>0.798117</td><td>0.859585</td><td>0.798117</td><td>0.122762</td><td>4.6045</td><td>6.858155</td><td>4.6045</td><td>6.858155</td><td>4.63575</td><td>5.04872</td><td>4.63575</td><td>5.04872</td><td>71.684</td><td>63.882308</td><td>71.684</td><td>63.882308</td><td>23.382</td><td>22.542859</td><td>23.382</td><td>22.542859</td><td>95.066</td><td>56.763902</td><td>95.066</td><td>56.763902</td><td>-0.147059</td><td>0.765947</td><td>-0.147059</td><td>0.765947</td><td>0.298831</td><td>0.619694</td><td>0.298831</td><td>0.619694</td></tr><tr><td>0.184046</td><td>0.286078</td><td>0.038548</td><td>0.220992</td><td>-0.38339</td><td>0.086839</td><td>0.673395</td><td>1.182823</td><td>0.065162</td><td>1.010712</td><td>-0.323887</td><td>0.002133</td><td>-0.483244</td><td>0.528421</td><td>1.913289</td><td>-0.103435</td><td>-0.147323</td><td>-0.177636</td><td>2.550381</td><td>0.511809</td><td>0.033</td><td>14.178</td><td>43.8</td><td>49.836</td><td>93.636</td><td>1.050577</td><td>-0.237891</td><td>1.0734e-9</td><td>-0.064359</td><td>0.023939</td><td>-0.308402</td><td>-0.341364</td><td>0.220629</td><td>-0.259154</td><td>-0.030559</td><td>0.406146</td><td>0.467874</td><td>&hellip;</td><td>706.574808</td><td>4666.443696</td><td>0.878883</td><td>0.532231</td><td>4.550038</td><td>0.064462</td><td>-0.995356</td><td>-0.064462</td><td>0.151769</td><td>3.6902</td><td>6.281356</td><td>3.6902</td><td>6.281356</td><td>6.5442</td><td>6.109671</td><td>6.5442</td><td>6.109671</td><td>66.1072</td><td>56.711687</td><td>66.1072</td><td>56.711687</td><td>28.6728</td><td>22.827576</td><td>28.6728</td><td>22.827576</td><td>94.78</td><td>49.163141</td><td>94.78</td><td>49.163141</td><td>-0.316719</td><td>0.764152</td><td>-0.316719</td><td>0.764152</td><td>0.226172</td><td>0.560725</td><td>0.226172</td><td>0.560725</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 77)\n",
       "┌───────────┬──────────┬──────────┬──────────┬───┬────────────┬────────────┬───────────┬───────────┐\n",
       "│ X863      ┆ X856     ┆ X344     ┆ X598     ┆ … ┆ order_flow ┆ order_flow ┆ order_flo ┆ order_flo │\n",
       "│ ---       ┆ ---      ┆ ---      ┆ ---      ┆   ┆ _imbalance ┆ _imbalance ┆ w_imbalan ┆ w_imbalan │\n",
       "│ f64       ┆ f64      ┆ f64      ┆ f64      ┆   ┆ _ma_10     ┆ _std_10    ┆ ce_ma_60  ┆ ce_std_60 │\n",
       "│           ┆          ┆          ┆          ┆   ┆ ---        ┆ ---        ┆ ---       ┆ ---       │\n",
       "│           ┆          ┆          ┆          ┆   ┆ f64        ┆ f64        ┆ f64       ┆ f64       │\n",
       "╞═══════════╪══════════╪══════════╪══════════╪═══╪════════════╪════════════╪═══════════╪═══════════╡\n",
       "│ -0.270279 ┆ 0.888982 ┆ 0.183128 ┆ 1.002431 ┆ … ┆ -0.017812  ┆ 0.602563   ┆ -0.017812 ┆ 0.602563  │\n",
       "│ -0.356306 ┆ 0.174188 ┆ 1.252857 ┆ 0.395232 ┆ … ┆ 0.408264   ┆ 0.602563   ┆ 0.408264  ┆ 0.602563  │\n",
       "│ 0.268433  ┆ -0.26551 ┆ 0.084397 ┆ 0.092053 ┆ … ┆ 0.132402   ┆ 0.640188   ┆ 0.132402  ┆ 0.640188  │\n",
       "│ -0.364048 ┆ 1.247777 ┆ 0.488409 ┆ 0.320689 ┆ … ┆ 0.298831   ┆ 0.619694   ┆ 0.298831  ┆ 0.619694  │\n",
       "│ 0.184046  ┆ 0.286078 ┆ 0.038548 ┆ 0.220992 ┆ … ┆ 0.226172   ┆ 0.560725   ┆ 0.226172  ┆ 0.560725  │\n",
       "└───────────┴──────────┴──────────┴──────────┴───┴────────────┴────────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import lightgbm as lgb\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create weights\n",
    "weights = create_time_decay_weights(len(df_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_train['label'].to_numpy()\n",
    "X = df_train.drop('label').to_numpy()\n",
    "\n",
    "# num_test = int(X.shape[0] * 0.2)\n",
    "# train_X, train_y = X[:-num_test], y[:-num_test]\n",
    "# valid_X, valid_y = X[-num_test:], y[-num_test:]\n",
    "\n",
    "# train_weights = weights[:-num_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Optuna to find the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((525887, 77), (525887,))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train_add.to_numpy()\n",
    "y = labels.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Optuna hyperparameter search\n",
    "def objective(trial):\n",
    "  num_test = int(X.shape[0] * 0.2)\n",
    "  train_X, train_y = X[:-num_test], y[:-num_test]\n",
    "  valid_X, valid_y = X[-num_test:], y[-num_test:]\n",
    "\n",
    "  dtrain = lgb.Dataset(train_X, label=train_y)\n",
    "\n",
    "  params = {\n",
    "    \"objective\": \"regression\",\n",
    "    \"metric\": trial.suggest_categorical(\"metric\", ['rmse', 'l1', 'l2']),\n",
    "    \"verbosity\": -1,\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n",
    "    \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n",
    "    \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n",
    "    \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\n",
    "    \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\n",
    "    \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
    "    \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "  }\n",
    "\n",
    "  gbm = lgb.train(params, dtrain)\n",
    "  preds = gbm.predict(valid_X)\n",
    "  correlation = pearsonr(preds, valid_y).statistic\n",
    "  return correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 18:55:55,783] A new study created in memory with name: no-name-76c6b632-7f89-42f3-b77a-41c818fb9fe9\n",
      "[I 2025-07-11 18:55:57,712] Trial 0 finished with value: 0.025552969417324708 and parameters: {'metric': 'l1', 'lambda_l1': 3.2469963065435246e-07, 'lambda_l2': 1.31301932373552e-07, 'num_leaves': 96, 'feature_fraction': 0.7092315778966206, 'bagging_fraction': 0.6116219737428109, 'bagging_freq': 5, 'min_child_samples': 27}. Best is trial 0 with value: 0.025552969417324708.\n",
      "[I 2025-07-11 18:56:00,176] Trial 1 finished with value: 0.01868931957686936 and parameters: {'metric': 'l2', 'lambda_l1': 0.8905710683121216, 'lambda_l2': 1.7885688834874514, 'num_leaves': 223, 'feature_fraction': 0.42333073556158085, 'bagging_fraction': 0.9527305293421438, 'bagging_freq': 6, 'min_child_samples': 85}. Best is trial 0 with value: 0.025552969417324708.\n",
      "[I 2025-07-11 18:56:02,687] Trial 2 finished with value: 0.0058303368238378185 and parameters: {'metric': 'rmse', 'lambda_l1': 7.000180248125859, 'lambda_l2': 0.04808570448417398, 'num_leaves': 179, 'feature_fraction': 0.7356502793475409, 'bagging_fraction': 0.4246522980907281, 'bagging_freq': 7, 'min_child_samples': 39}. Best is trial 0 with value: 0.025552969417324708.\n",
      "[I 2025-07-11 18:56:05,368] Trial 3 finished with value: 0.011962140127015079 and parameters: {'metric': 'l1', 'lambda_l1': 1.2174590682325581e-06, 'lambda_l2': 1.0935461778843496e-05, 'num_leaves': 217, 'feature_fraction': 0.6869732119387858, 'bagging_fraction': 0.5485276758612473, 'bagging_freq': 3, 'min_child_samples': 15}. Best is trial 0 with value: 0.025552969417324708.\n",
      "[I 2025-07-11 18:56:07,420] Trial 4 finished with value: 0.02484373356534659 and parameters: {'metric': 'l1', 'lambda_l1': 2.1002543936497823e-05, 'lambda_l2': 7.152580754063436, 'num_leaves': 147, 'feature_fraction': 0.6679581756084569, 'bagging_fraction': 0.5164390130111145, 'bagging_freq': 5, 'min_child_samples': 47}. Best is trial 0 with value: 0.025552969417324708.\n",
      "[I 2025-07-11 18:56:10,059] Trial 5 finished with value: 0.03720160776765273 and parameters: {'metric': 'rmse', 'lambda_l1': 1.385329763016804e-07, 'lambda_l2': 1.0849783445348903e-08, 'num_leaves': 241, 'feature_fraction': 0.6340188959329374, 'bagging_fraction': 0.6613343191563743, 'bagging_freq': 4, 'min_child_samples': 24}. Best is trial 5 with value: 0.03720160776765273.\n",
      "[I 2025-07-11 18:56:12,710] Trial 6 finished with value: 0.021626819886984082 and parameters: {'metric': 'l1', 'lambda_l1': 1.1052056823669196e-08, 'lambda_l2': 4.5823745307960925e-06, 'num_leaves': 249, 'feature_fraction': 0.6818863745937823, 'bagging_fraction': 0.7052100508814313, 'bagging_freq': 2, 'min_child_samples': 90}. Best is trial 5 with value: 0.03720160776765273.\n",
      "[I 2025-07-11 18:56:13,821] Trial 7 finished with value: 0.020552074452198563 and parameters: {'metric': 'l1', 'lambda_l1': 1.140015794259533e-08, 'lambda_l2': 0.0007682612544371893, 'num_leaves': 2, 'feature_fraction': 0.6583806016318186, 'bagging_fraction': 0.5621937001840496, 'bagging_freq': 7, 'min_child_samples': 45}. Best is trial 5 with value: 0.03720160776765273.\n",
      "[I 2025-07-11 18:56:15,909] Trial 8 finished with value: 0.02588671047354168 and parameters: {'metric': 'l1', 'lambda_l1': 0.028312291500011785, 'lambda_l2': 1.0166316275972363e-08, 'num_leaves': 185, 'feature_fraction': 0.5140714685407777, 'bagging_fraction': 0.6612473337366584, 'bagging_freq': 5, 'min_child_samples': 59}. Best is trial 5 with value: 0.03720160776765273.\n",
      "[I 2025-07-11 18:56:17,981] Trial 9 finished with value: 0.03831970234630397 and parameters: {'metric': 'l1', 'lambda_l1': 0.0021980425716998445, 'lambda_l2': 8.08748901347971e-06, 'num_leaves': 121, 'feature_fraction': 0.6776788396863254, 'bagging_fraction': 0.82832406154343, 'bagging_freq': 4, 'min_child_samples': 15}. Best is trial 9 with value: 0.03831970234630397.\n",
      "[I 2025-07-11 18:56:20,081] Trial 10 finished with value: 0.015571706075420728 and parameters: {'metric': 'l2', 'lambda_l1': 0.0011322053503579031, 'lambda_l2': 0.0008438456800328095, 'num_leaves': 74, 'feature_fraction': 0.9264139871525364, 'bagging_fraction': 0.85773312851179, 'bagging_freq': 1, 'min_child_samples': 8}. Best is trial 9 with value: 0.03831970234630397.\n",
      "[I 2025-07-11 18:56:22,319] Trial 11 finished with value: 0.034898802760227304 and parameters: {'metric': 'rmse', 'lambda_l1': 0.001237620561088997, 'lambda_l2': 9.075173077937477e-07, 'num_leaves': 116, 'feature_fraction': 0.8481858424933235, 'bagging_fraction': 0.7836071756346015, 'bagging_freq': 3, 'min_child_samples': 24}. Best is trial 9 with value: 0.03831970234630397.\n",
      "[I 2025-07-11 18:56:23,754] Trial 12 finished with value: 0.040246522053418554 and parameters: {'metric': 'rmse', 'lambda_l1': 4.343199693104358e-05, 'lambda_l2': 1.6615420189895647e-08, 'num_leaves': 35, 'feature_fraction': 0.5063780675831886, 'bagging_fraction': 0.7800847179846898, 'bagging_freq': 4, 'min_child_samples': 5}. Best is trial 12 with value: 0.040246522053418554.\n",
      "[I 2025-07-11 18:56:25,091] Trial 13 finished with value: 0.024339682878165046 and parameters: {'metric': 'rmse', 'lambda_l1': 4.4130379077314466e-05, 'lambda_l2': 5.1777119369199796e-05, 'num_leaves': 25, 'feature_fraction': 0.5097978729871985, 'bagging_fraction': 0.8493017305234358, 'bagging_freq': 4, 'min_child_samples': 7}. Best is trial 12 with value: 0.040246522053418554.\n",
      "[I 2025-07-11 18:56:26,720] Trial 14 finished with value: 0.008199142249449686 and parameters: {'metric': 'rmse', 'lambda_l1': 0.02725414095762572, 'lambda_l2': 2.131324000552577e-07, 'num_leaves': 59, 'feature_fraction': 0.540470294727839, 'bagging_fraction': 0.9657619303161833, 'bagging_freq': 3, 'min_child_samples': 66}. Best is trial 12 with value: 0.040246522053418554.\n",
      "[I 2025-07-11 18:56:28,371] Trial 15 finished with value: 0.01881837834806274 and parameters: {'metric': 'l2', 'lambda_l1': 6.72409554042409e-05, 'lambda_l2': 0.00866346695667006, 'num_leaves': 47, 'feature_fraction': 0.8166680408755531, 'bagging_fraction': 0.7642412051693184, 'bagging_freq': 2, 'min_child_samples': 31}. Best is trial 12 with value: 0.040246522053418554.\n",
      "[I 2025-07-11 18:56:30,273] Trial 16 finished with value: 0.0331466107249765 and parameters: {'metric': 'rmse', 'lambda_l1': 0.013112922420583418, 'lambda_l2': 6.901890519668026e-05, 'num_leaves': 149, 'feature_fraction': 0.4095820152552473, 'bagging_fraction': 0.8778256657156904, 'bagging_freq': 4, 'min_child_samples': 72}. Best is trial 12 with value: 0.040246522053418554.\n",
      "[I 2025-07-11 18:56:32,083] Trial 17 finished with value: 0.01630008720967807 and parameters: {'metric': 'l1', 'lambda_l1': 7.103693015117655e-06, 'lambda_l2': 9.97252627797489e-08, 'num_leaves': 93, 'feature_fraction': 0.590778277853657, 'bagging_fraction': 0.7775792136001902, 'bagging_freq': 6, 'min_child_samples': 15}. Best is trial 12 with value: 0.040246522053418554.\n",
      "[I 2025-07-11 18:56:33,526] Trial 18 finished with value: 0.045916320221725586 and parameters: {'metric': 'rmse', 'lambda_l1': 0.0005429364761107174, 'lambda_l2': 1.903476016894585e-06, 'num_leaves': 9, 'feature_fraction': 0.7740564435417563, 'bagging_fraction': 0.9098631126601334, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 18 with value: 0.045916320221725586.\n",
      "[I 2025-07-11 18:56:35,034] Trial 19 finished with value: 0.023342901870205608 and parameters: {'metric': 'rmse', 'lambda_l1': 0.00018035687436256662, 'lambda_l2': 2.012213814662514e-06, 'num_leaves': 4, 'feature_fraction': 0.9994777484879818, 'bagging_fraction': 0.9214484748241984, 'bagging_freq': 1, 'min_child_samples': 33}. Best is trial 18 with value: 0.045916320221725586.\n",
      "[I 2025-07-11 18:56:36,606] Trial 20 finished with value: 0.04685874356880335 and parameters: {'metric': 'rmse', 'lambda_l1': 0.23301311031427047, 'lambda_l2': 5.711956168690335e-08, 'num_leaves': 31, 'feature_fraction': 0.7810804226229294, 'bagging_fraction': 0.725237500930573, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 20 with value: 0.04685874356880335.\n",
      "[I 2025-07-11 18:56:38,359] Trial 21 finished with value: 0.012671106846908108 and parameters: {'metric': 'rmse', 'lambda_l1': 0.28920203712597226, 'lambda_l2': 3.9463020541096446e-08, 'num_leaves': 34, 'feature_fraction': 0.7844603625653732, 'bagging_fraction': 0.9993417734943602, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 20 with value: 0.04685874356880335.\n",
      "[I 2025-07-11 18:56:39,940] Trial 22 finished with value: 0.043849787244506014 and parameters: {'metric': 'rmse', 'lambda_l1': 4.859650054342868e-06, 'lambda_l2': 5.761189364653121e-07, 'num_leaves': 24, 'feature_fraction': 0.8800158361838495, 'bagging_fraction': 0.7401448547687126, 'bagging_freq': 1, 'min_child_samples': 17}. Best is trial 20 with value: 0.04685874356880335.\n",
      "[I 2025-07-11 18:56:41,411] Trial 23 finished with value: 0.04373567070564513 and parameters: {'metric': 'rmse', 'lambda_l1': 4.738293262335701e-06, 'lambda_l2': 7.54820960680218e-07, 'num_leaves': 16, 'feature_fraction': 0.8820805379740139, 'bagging_fraction': 0.7159832920748979, 'bagging_freq': 1, 'min_child_samples': 18}. Best is trial 20 with value: 0.04685874356880335.\n",
      "[I 2025-07-11 18:56:43,448] Trial 24 finished with value: 0.023583822920209697 and parameters: {'metric': 'rmse', 'lambda_l1': 0.34011496098635724, 'lambda_l2': 5.201402407150518e-07, 'num_leaves': 61, 'feature_fraction': 0.9405104058686253, 'bagging_fraction': 0.9075730258947843, 'bagging_freq': 2, 'min_child_samples': 17}. Best is trial 20 with value: 0.04685874356880335.\n",
      "[I 2025-07-11 18:56:45,273] Trial 25 finished with value: 0.03899124454779692 and parameters: {'metric': 'rmse', 'lambda_l1': 7.892852232427978, 'lambda_l2': 3.117989083397074e-05, 'num_leaves': 80, 'feature_fraction': 0.7835619500520222, 'bagging_fraction': 0.6282810459149972, 'bagging_freq': 1, 'min_child_samples': 37}. Best is trial 20 with value: 0.04685874356880335.\n",
      "[I 2025-07-11 18:56:47,056] Trial 26 finished with value: 0.04301106346474201 and parameters: {'metric': 'rmse', 'lambda_l1': 0.0045076294884696935, 'lambda_l2': 7.699767993135156e-08, 'num_leaves': 51, 'feature_fraction': 0.7638402939258676, 'bagging_fraction': 0.7419086315708714, 'bagging_freq': 2, 'min_child_samples': 12}. Best is trial 20 with value: 0.04685874356880335.\n",
      "[I 2025-07-11 18:56:48,399] Trial 27 finished with value: 0.050368266287051565 and parameters: {'metric': 'l2', 'lambda_l1': 0.0004025744541416658, 'lambda_l2': 2.658383514719199e-06, 'num_leaves': 23, 'feature_fraction': 0.8718197529063584, 'bagging_fraction': 0.45952494695797863, 'bagging_freq': 1, 'min_child_samples': 99}. Best is trial 27 with value: 0.050368266287051565.\n",
      "[I 2025-07-11 18:56:49,846] Trial 28 finished with value: 0.019940269584879163 and parameters: {'metric': 'l2', 'lambda_l1': 0.0002858169877546152, 'lambda_l2': 0.0001783764887518385, 'num_leaves': 43, 'feature_fraction': 0.8225651516622092, 'bagging_fraction': 0.43814758316844477, 'bagging_freq': 3, 'min_child_samples': 76}. Best is trial 27 with value: 0.050368266287051565.\n",
      "[I 2025-07-11 18:56:51,666] Trial 29 finished with value: 0.042419954521717665 and parameters: {'metric': 'l2', 'lambda_l1': 0.11214525596200361, 'lambda_l2': 2.6762882503287755e-06, 'num_leaves': 102, 'feature_fraction': 0.7279962600672727, 'bagging_fraction': 0.46169210167801944, 'bagging_freq': 2, 'min_child_samples': 56}. Best is trial 27 with value: 0.050368266287051565.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 30\n",
      "Best trial:\n",
      "  Value: 0.050368266287051565\n",
      "  Params: \n",
      "    metric: l2\n",
      "    lambda_l1: 0.0004025744541416658\n",
      "    lambda_l2: 2.658383514719199e-06\n",
      "    num_leaves: 23\n",
      "    feature_fraction: 0.8718197529063584\n",
      "    bagging_fraction: 0.45952494695797863\n",
      "    bagging_freq: 1\n",
      "    min_child_samples: 99\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n",
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = lgb.Dataset(X, label=y, weight=weights)\n",
    "\n",
    "params = {\n",
    "  \"objective\": \"regression\",\n",
    "  \"metric\": \"l2\",\n",
    "  \"verbosity\": -1,\n",
    "  \"boosting_type\": \"gbdt\",\n",
    "  \"lambda_l1\": 1.9944400955988304e-07,\n",
    "  \"lambda_l2\": 0.010561219417605745,\n",
    "  \"num_leaves\": 62,\n",
    "  \"feature_fraction\": 0.6126623123764985,\n",
    "  \"bagging_fraction\": 0.8564319694337191,\n",
    "  \"bagging_freq\": 3,\n",
    "  \"min_child_samples\": 80,\n",
    "}\n",
    "\n",
    "gbm = lgb.train(params, dtrain)\n",
    "# preds = gbm.predict(valid_X)\n",
    "# correlation = pearsonr(preds, valid_y).statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9551323843131287"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = gbm.predict(valid_X)\n",
    "correlation = pearsonr(preds, valid_y).statistic\n",
    "correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('models/other_lgbm.pkl', 'wb') as f:\n",
    "  pickle.dump(gbm, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "standard = 0.8401975707471385"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make prediction on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('models/other_lgbm.pkl', 'rb') as f:\n",
    "  loaded_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = gbm.predict(df_test.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.31340408,  0.57086042, -0.04478809, ..., -0.09120982,\n",
       "        0.0136488 ,  0.53911284])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pl.DataFrame({\n",
    "  'ID': range(1, df_test.shape[0]+1),\n",
    "  'prediction': preds\n",
    "})\n",
    "scores.write_csv(\"results/lgbm_rolling.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: 2025-07-10T16:47:55.154475+08:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.11.9\n",
      "IPython version      : 8.31.0\n",
      "\n",
      "Compiler    : MSC v.1938 64 bit (AMD64)\n",
      "OS          : Windows\n",
      "Release     : 10\n",
      "Machine     : AMD64\n",
      "Processor   : Intel64 Family 6 Model 183 Stepping 1, GenuineIntel\n",
      "CPU cores   : 20\n",
      "Architecture: 64bit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
